{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14283b70",
   "metadata": {
    "id": "14283b70",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy import interpolate\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "461fc2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data.dataset import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import scipy.linalg as slin\n",
    "import scipy.sparse as sp\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from pandas import ExcelWriter\n",
    "from pandas import ExcelFile\n",
    "import glob\n",
    "import re\n",
    "import math\n",
    "from torch.optim.adam import Adam\n",
    "from utils import *\n",
    "from statistics import mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07bc1d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_lsem_dynamic(W_all,Z: nx.DiGraph,\n",
    "                 n: int,n_time:int, treatment_type: str,\n",
    "                 noise_scale: float = 0.5,\n",
    "                 baseline: float = 1.0) -> np.ndarray:\n",
    "    \"\"\"Simulate samples from LSEM.\n",
    "        \n",
    "        Args:\n",
    "        W_all,A: weigthed DAG for instaneous relation and lagged relation\n",
    "        n: number of samples in each time-stamp\n",
    "        lag: degree of AR\n",
    "        n_time: number of time stamp\n",
    "        treatment_type: the type of the exposure {Binary, Gaussian}\n",
    "        noise_scale: noise scale parameter of Gaussian distribution in the lSEM\n",
    "        baseline: the baseline for the outcome\n",
    "        \n",
    "        Returns:\n",
    "        X: [time,n, d] sample matrix\n",
    "        \"\"\"\n",
    "    #W_array = nx.to_numpy_array(W)\n",
    "    Z_array = nx.to_numpy_array(Z)\n",
    "    d = Z_array.shape[0]\n",
    "    #X_all = np.zeros([n_time+1,n, d])\n",
    "    \n",
    "    ## create the initial data\n",
    "    X = np.zeros([n, d])\n",
    "    W_0=W_all[0,:,:]\n",
    "    ordered_vertices = list(nx.topological_sort(nx.from_numpy_matrix(W_0,create_using=nx.DiGraph)))\n",
    "    assert len(ordered_vertices) == d\n",
    "    rank_A = ordered_vertices.index(0)\n",
    "    for j in ordered_vertices:\n",
    "        if ordered_vertices.index(j) > rank_A:\n",
    "            parents = list(nx.from_numpy_matrix(W_0,create_using=nx.DiGraph).predecessors(j))\n",
    "            X[:, j] = X[:, parents].dot(W_0[parents, j]) + np.random.normal(scale=noise_scale, size=n)\n",
    "        elif ordered_vertices.index(j) < rank_A:\n",
    "            X[:, j] = np.random.normal(scale=noise_scale, size=n)\n",
    "        else:\n",
    "            if treatment_type == 'Binary':\n",
    "                X[:, j] = 2 * (np.random.binomial(1, 0.5, n) - 0.5)\n",
    "            elif treatment_type == 'Gaussian':\n",
    "                X[:, j] = np.random.normal(scale=noise_scale, size=n)\n",
    "            else:\n",
    "                raise ValueError('unknown exposure type')\n",
    "    X[:, d-1] += baseline\n",
    "    X_all=X\n",
    "    ## for follow-up time-stamps, X=XW+AZ+E\n",
    "    for time in range(1,n_time+1):\n",
    "        X_temp = np.matmul(X,Z_array)\n",
    "        W_array=W_all[time,:,:] ## different index!\n",
    "        W=nx.from_numpy_matrix(W_array,create_using=nx.DiGraph)\n",
    "        for j in ordered_vertices:\n",
    "            if ordered_vertices.index(j) > rank_A:\n",
    "                parents = list(W.predecessors(j))\n",
    "                X_temp[:, j] += X_temp[:, parents].dot(W_array[parents, j]) + np.random.normal(scale=noise_scale, size=n)\n",
    "            elif ordered_vertices.index(j) < rank_A:\n",
    "                X_temp[:, j] += np.random.normal(scale=noise_scale, size=n)\n",
    "            else:\n",
    "                if treatment_type == 'Binary':\n",
    "                    X_temp[:, j] += 2 * (np.random.binomial(1, 0.5, n) - 0.5)\n",
    "                elif treatment_type == 'Gaussian':\n",
    "                    X_temp[:, j] += np.random.normal(scale=noise_scale, size=n)\n",
    "                else:\n",
    "                    raise ValueError('unknown exposure type')\n",
    "        X_all=np.append(X_all,X_temp,axis=0)\n",
    "        X=X_temp\n",
    "    return X_all\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7f0a83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "def cos(x):\n",
    "    return((-15+(5-x)**2)/15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d1935f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_all=np.zeros([11,5, 5])\n",
    "for i in range(11):\n",
    "    W_all[i,0,4]=cos(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "514b04ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create Z matrix\n",
    "Z=np.identity(5)\n",
    "Z[0,0]=0 # no correlation for treatment\n",
    "Z_graph=nx.from_numpy_matrix(Z,create_using=nx.DiGraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b20ee4",
   "metadata": {
    "id": "94b20ee4"
   },
   "source": [
    "## piecewise ANOCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1766d8b",
   "metadata": {
    "id": "f1766d8b"
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import time\n",
    "import argparse\n",
    "import pickle\n",
    "import os\n",
    "import random\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import math\n",
    "from utils import *\n",
    "\n",
    "from multiprocessing import Pool\n",
    "import multiprocessing\n",
    "n_cores = multiprocessing.cpu_count()\n",
    "from numpy.random import randn\n",
    "from random import seed as rseed\n",
    "from numpy.random import seed as npseed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d67102b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute constraint h(A) value\n",
    "def _h_A(A, m):\n",
    "    expm_A = matrix_poly(A*A, m)\n",
    "    h_A = torch.trace(expm_A) - m\n",
    "    return h_A\n",
    "\n",
    "prox_plus = torch.nn.Threshold(0.,0.)\n",
    "\n",
    "def stau(w, tau):\n",
    "    w1 = prox_plus(torch.abs(w)-tau)\n",
    "    return torch.sign(w)*w1\n",
    "\n",
    "\n",
    "def update_optimizer(optimizer, original_lr, c_A):\n",
    "    '''related LR to c_A, whenever c_A gets big, reduce LR proportionally'''\n",
    "    MAX_LR = 1e-2\n",
    "    MIN_LR = 1e-4\n",
    "\n",
    "    estimated_lr = original_lr / (math.log10(c_A) + 1e-10)\n",
    "    if estimated_lr > MAX_LR:\n",
    "        lr = MAX_LR\n",
    "    elif estimated_lr < MIN_LR:\n",
    "        lr = MIN_LR\n",
    "    else:\n",
    "        lr = estimated_lr\n",
    "\n",
    "    # set LR\n",
    "    for parame_group in optimizer.param_groups:\n",
    "        parame_group['lr'] = lr\n",
    "\n",
    "    return optimizer, lr\n",
    "\n",
    "#===================================\n",
    "# training:\n",
    "#===================================\n",
    "\n",
    "def train(epoch, lambda_A, c_A, optimizer,old_lr):\n",
    "    t = time.time()\n",
    "    nll_train = []\n",
    "    kl_train = []\n",
    "    mse_train = []\n",
    "    shd_trian = []\n",
    "\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    scheduler.step()\n",
    "\n",
    "\n",
    "    # update optimizer\n",
    "    optimizer, lr = update_optimizer(optimizer, old_lr, c_A)\n",
    "\n",
    "\n",
    "    for batch_idx, (data, relations) in enumerate(train_loader):\n",
    "\n",
    "#         if args.cuda:\n",
    "#             data, relations = data.cuda(), relations.cuda()\n",
    "        data, relations = Variable(data).double(), Variable(relations).double()\n",
    "\n",
    "        # reshape data\n",
    "        relations = relations.unsqueeze(2)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        enc_x, logits, origin_A, adj_A_tilt_encoder, z_gap, z_positive, myA, Wa = encoder(data, rel_rec, rel_send)  # logits is of size: [num_sims, z_dims]\n",
    "        edges = logits\n",
    "\n",
    "        dec_x, output, adj_A_tilt_decoder = decoder(data, edges,d * x_dims, rel_rec, rel_send, origin_A, adj_A_tilt_encoder, Wa)\n",
    "\n",
    "        if torch.sum(output != output):\n",
    "            print('nan error\\n')\n",
    "\n",
    "        target = data\n",
    "        preds = output\n",
    "        variance = 0.\n",
    "\n",
    "        # reconstruction accuracy loss\n",
    "        loss_nll = nll_gaussian(preds, target, variance)\n",
    "\n",
    "        # KL loss\n",
    "        loss_kl = kl_gaussian(logits)\n",
    "\n",
    "        # ELBO loss:\n",
    "        loss = loss_kl + loss_nll\n",
    "\n",
    "        # add A loss\n",
    "        one_adj_A = origin_A # torch.mean(adj_A_tilt_decoder, dim =0)\n",
    "        sparse_loss = tau_A * torch.sum(torch.abs(one_adj_A))\n",
    "\n",
    "        # compute h(A)\n",
    "        h_A = _h_A(origin_A, d)\n",
    "        loss += lambda_A * h_A + 0.5 * c_A * h_A * h_A + 100. * torch.trace(origin_A*origin_A) + sparse_loss #+  0.01 * torch.sum(variance * variance)\n",
    "\n",
    "\n",
    "        loss.backward()\n",
    "        loss = optimizer.step()\n",
    "\n",
    "        myA.data = stau(myA.data, tau_A*lr)\n",
    "\n",
    "\n",
    "        mse_train.append(F.mse_loss(preds, target).item())\n",
    "        nll_train.append(loss_nll.item())\n",
    "        kl_train.append(loss_kl.item())\n",
    "\n",
    "    #print(h_A.item())\n",
    "\n",
    "    return np.mean(np.mean(kl_train)  + np.mean(nll_train)), np.mean(nll_train), np.mean(mse_train), origin_A, optimizer, lr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f5eef9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "913812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ELBO Loss : 0.0005794695438621972\n",
      "Best NLL Loss : 1.9590812679450736e-06\n",
      "Best MSE Loss : 7.836325071780294e-07\n",
      "0\n",
      "Best ELBO Loss : 0.0014366148137122383\n",
      "Best NLL Loss : 2.3761866370435904e-06\n",
      "Best MSE Loss : 9.50474654817436e-07\n",
      "1\n",
      "Best ELBO Loss : 0.0009965669656927683\n",
      "Best NLL Loss : 1.189070799187383e-06\n",
      "Best MSE Loss : 4.756283196749532e-07\n",
      "2\n",
      "Best ELBO Loss : 0.0012024249234417487\n",
      "Best NLL Loss : 1.9926711341894157e-06\n",
      "Best MSE Loss : 7.970684536757664e-07\n",
      "3\n",
      "Best ELBO Loss : 0.0018730432029432356\n",
      "Best NLL Loss : 1.2933395226921396e-05\n",
      "Best MSE Loss : 5.173358090768558e-06\n",
      "4\n",
      "Best ELBO Loss : 0.0028443011407482607\n",
      "Best NLL Loss : 9.684378318574063e-06\n",
      "Best MSE Loss : 3.873751327429625e-06\n",
      "5\n",
      "Best ELBO Loss : 0.003380170692126821\n",
      "Best NLL Loss : 1.8470354041773215e-05\n",
      "Best MSE Loss : 7.388141616709286e-06\n",
      "6\n",
      "Best ELBO Loss : 0.0035473492991382888\n",
      "Best NLL Loss : 5.916372095374205e-06\n",
      "Best MSE Loss : 2.3665488381496818e-06\n",
      "7\n",
      "Best ELBO Loss : 0.003869503730171744\n",
      "Best NLL Loss : 6.427307607523299e-06\n",
      "Best MSE Loss : 2.5709230430093196e-06\n",
      "8\n",
      "Best ELBO Loss : 0.004791849336738295\n",
      "Best NLL Loss : 9.334666693511332e-06\n",
      "Best MSE Loss : 3.733866677404532e-06\n",
      "9\n",
      "0\n",
      "374400\n",
      "Best ELBO Loss : 0.0009734358934997492\n",
      "Best NLL Loss : 8.853341536607589e-07\n",
      "Best MSE Loss : 3.5413366146430355e-07\n",
      "0\n",
      "Best ELBO Loss : 0.002169100503646142\n",
      "Best NLL Loss : 5.446681059424473e-06\n",
      "Best MSE Loss : 2.178672423769789e-06\n",
      "1\n",
      "Best ELBO Loss : 0.0015082701184815684\n",
      "Best NLL Loss : 2.2191958723632252e-06\n",
      "Best MSE Loss : 8.876783489452899e-07\n",
      "2\n",
      "Best ELBO Loss : 0.002272821181995791\n",
      "Best NLL Loss : 6.068908782958447e-06\n",
      "Best MSE Loss : 2.4275635131833788e-06\n",
      "3\n",
      "Best ELBO Loss : 0.0023767763311621773\n",
      "Best NLL Loss : 4.552779369811164e-06\n",
      "Best MSE Loss : 1.8211117479244657e-06\n",
      "4\n",
      "Best ELBO Loss : 0.0022778591252951585\n",
      "Best NLL Loss : 5.7991412058962265e-06\n",
      "Best MSE Loss : 2.3196564823584905e-06\n",
      "5\n",
      "Best ELBO Loss : 0.003254523693923107\n",
      "Best NLL Loss : 7.455813138518719e-06\n",
      "Best MSE Loss : 2.982325255407487e-06\n",
      "6\n",
      "Best ELBO Loss : 0.003102886187754643\n",
      "Best NLL Loss : 6.382853904686577e-06\n",
      "Best MSE Loss : 2.553141561874631e-06\n",
      "7\n",
      "Best ELBO Loss : 0.0037610100978079726\n",
      "Best NLL Loss : 6.588364263312738e-06\n",
      "Best MSE Loss : 2.635345705325095e-06\n",
      "8\n",
      "Best ELBO Loss : 0.003787105193225574\n",
      "Best NLL Loss : 8.025849291599403e-06\n",
      "Best MSE Loss : 3.210339716639761e-06\n",
      "9\n",
      "1\n",
      "343669\n",
      "Best ELBO Loss : 0.0009526270036166536\n",
      "Best NLL Loss : 7.003908554524928e-07\n",
      "Best MSE Loss : 2.8015634218099713e-07\n",
      "0\n",
      "Best ELBO Loss : 0.0014757405866500234\n",
      "Best NLL Loss : 2.836265313748881e-06\n",
      "Best MSE Loss : 1.1345061254995525e-06\n",
      "1\n",
      "Best ELBO Loss : 0.001358556128385567\n",
      "Best NLL Loss : 1.7637620135164312e-06\n",
      "Best MSE Loss : 7.055048054065726e-07\n",
      "2\n",
      "Best ELBO Loss : 0.0022473265555486657\n",
      "Best NLL Loss : 8.657447153262968e-06\n",
      "Best MSE Loss : 3.4629788613051872e-06\n",
      "3\n",
      "Best ELBO Loss : 0.002762401588242897\n",
      "Best NLL Loss : 1.2310617897464296e-05\n",
      "Best MSE Loss : 4.924247158985718e-06\n",
      "4\n",
      "Best ELBO Loss : 0.0037424086849062468\n",
      "Best NLL Loss : 1.324143588957814e-05\n",
      "Best MSE Loss : 5.296574355831256e-06\n",
      "5\n",
      "Best ELBO Loss : 0.004641824102378878\n",
      "Best NLL Loss : 2.0746585364890275e-05\n",
      "Best MSE Loss : 8.298634145956111e-06\n",
      "6\n",
      "Best ELBO Loss : 0.004591583673183715\n",
      "Best NLL Loss : 2.322531358232993e-05\n",
      "Best MSE Loss : 9.290125432931971e-06\n",
      "7\n",
      "Best ELBO Loss : 0.006746461181179594\n",
      "Best NLL Loss : 1.2613979613562004e-05\n",
      "Best MSE Loss : 5.045591845424801e-06\n",
      "8\n",
      "Best ELBO Loss : 0.004244877959315937\n",
      "Best NLL Loss : 1.1913982527915338e-05\n",
      "Best MSE Loss : 4.765593011166136e-06\n",
      "9\n",
      "2\n",
      "289095\n",
      "Best ELBO Loss : 0.0028891718121499517\n",
      "Best NLL Loss : 1.0391511513358989e-05\n",
      "Best MSE Loss : 4.156604605343595e-06\n",
      "0\n",
      "Best ELBO Loss : 0.003237901438867683\n",
      "Best NLL Loss : 1.0724012914404446e-05\n",
      "Best MSE Loss : 4.289605165761778e-06\n",
      "1\n",
      "Best ELBO Loss : 0.0024387123387167916\n",
      "Best NLL Loss : 5.279779178008797e-06\n",
      "Best MSE Loss : 2.1119116712035184e-06\n",
      "2\n",
      "Best ELBO Loss : 0.0030606366817396828\n",
      "Best NLL Loss : 7.89093725039377e-06\n",
      "Best MSE Loss : 3.156374900157508e-06\n",
      "3\n",
      "Best ELBO Loss : 0.0035056540154083933\n",
      "Best NLL Loss : 1.071049498131405e-05\n",
      "Best MSE Loss : 4.2841979925256194e-06\n",
      "4\n",
      "Best ELBO Loss : 0.0033274212819281476\n",
      "Best NLL Loss : 6.177501463098496e-06\n",
      "Best MSE Loss : 2.4710005852393987e-06\n",
      "5\n",
      "Best ELBO Loss : 0.0034706720543282174\n",
      "Best NLL Loss : 8.654842808668305e-06\n",
      "Best MSE Loss : 3.461937123467322e-06\n",
      "6\n",
      "Best ELBO Loss : 0.003977501023590103\n",
      "Best NLL Loss : 1.0438296887639836e-05\n",
      "Best MSE Loss : 4.175318755055935e-06\n",
      "7\n",
      "Best ELBO Loss : 0.003939516933123029\n",
      "Best NLL Loss : 1.166522624024283e-05\n",
      "Best MSE Loss : 4.666090496097132e-06\n",
      "8\n",
      "Best ELBO Loss : 0.003603419623584307\n",
      "Best NLL Loss : 8.176152885775936e-06\n",
      "Best MSE Loss : 3.270461154310374e-06\n",
      "9\n",
      "3\n",
      "235846\n",
      "Best ELBO Loss : 0.0009490903655171364\n",
      "Best NLL Loss : 7.0154266644148165e-06\n",
      "Best MSE Loss : 2.8061706657659263e-06\n",
      "0\n",
      "Best ELBO Loss : 0.001692416655280857\n",
      "Best NLL Loss : 1.4538597565164276e-05\n",
      "Best MSE Loss : 5.81543902606571e-06\n",
      "1\n",
      "Best ELBO Loss : 0.001909106743320908\n",
      "Best NLL Loss : 1.3614878831270339e-05\n",
      "Best MSE Loss : 5.445951532508137e-06\n",
      "2\n",
      "Best ELBO Loss : 0.0030053965136103457\n",
      "Best NLL Loss : 0.00014903593568735133\n",
      "Best MSE Loss : 5.961437427494053e-05\n",
      "3\n",
      "Best ELBO Loss : 0.0019494847951235903\n",
      "Best NLL Loss : 6.281646658979589e-06\n",
      "Best MSE Loss : 2.5126586635918357e-06\n",
      "4\n",
      "Best ELBO Loss : 0.00438074151011742\n",
      "Best NLL Loss : 1.8948822547180266e-05\n",
      "Best MSE Loss : 7.579529018872108e-06\n",
      "5\n",
      "Best ELBO Loss : 0.0038087664039878383\n",
      "Best NLL Loss : 7.525746987058092e-05\n",
      "Best MSE Loss : 3.010298794823237e-05\n",
      "6\n",
      "Best ELBO Loss : 0.003956307405695509\n",
      "Best NLL Loss : 2.3526296771295887e-05\n",
      "Best MSE Loss : 9.410518708518356e-06\n",
      "7\n",
      "Best ELBO Loss : 0.004358334792963568\n",
      "Best NLL Loss : 1.9613218583264512e-05\n",
      "Best MSE Loss : 7.845287433305805e-06\n",
      "8\n",
      "Best ELBO Loss : 0.0050297292682566375\n",
      "Best NLL Loss : 0.00023063988318981364\n",
      "Best MSE Loss : 9.225595327592546e-05\n",
      "9\n",
      "4\n",
      "432099\n",
      "Best ELBO Loss : 0.000928090269448513\n",
      "Best NLL Loss : 5.756573044735029e-07\n",
      "Best MSE Loss : 2.3026292178940118e-07\n",
      "0\n",
      "Best ELBO Loss : 0.0015072330478488071\n",
      "Best NLL Loss : 2.6507199392901027e-06\n",
      "Best MSE Loss : 1.0602879757160411e-06\n",
      "1\n",
      "Best ELBO Loss : 0.0013576299095324287\n",
      "Best NLL Loss : 2.5092965963125613e-06\n",
      "Best MSE Loss : 1.0037186385250246e-06\n",
      "2\n",
      "Best ELBO Loss : 0.0018980909637714579\n",
      "Best NLL Loss : 3.284590546333734e-06\n",
      "Best MSE Loss : 1.3138362185334934e-06\n",
      "3\n",
      "Best ELBO Loss : 0.002786774878995546\n",
      "Best NLL Loss : 1.0327586982984211e-05\n",
      "Best MSE Loss : 4.131034793193684e-06\n",
      "4\n",
      "Best ELBO Loss : 0.004818333270775775\n",
      "Best NLL Loss : 2.629636524167536e-05\n",
      "Best MSE Loss : 1.0518546096670144e-05\n",
      "5\n",
      "Best ELBO Loss : 0.004303075637756148\n",
      "Best NLL Loss : 5.156310559796625e-06\n",
      "Best MSE Loss : 2.0625242239186496e-06\n",
      "6\n",
      "Best ELBO Loss : 0.0061891542605025445\n",
      "Best NLL Loss : 0.00024314757351828384\n",
      "Best MSE Loss : 9.725902940731354e-05\n",
      "7\n",
      "Best ELBO Loss : 0.006753440474090346\n",
      "Best NLL Loss : 0.0005832792472651979\n",
      "Best MSE Loss : 0.00023331169890607913\n",
      "8\n",
      "Best ELBO Loss : 0.007046379113504644\n",
      "Best NLL Loss : 0.0006930243500899229\n",
      "Best MSE Loss : 0.00027720974003596913\n",
      "9\n",
      "5\n",
      "448097\n",
      "Best ELBO Loss : 0.0009028517160057051\n",
      "Best NLL Loss : 6.839747070737644e-07\n",
      "Best MSE Loss : 2.7358988282950577e-07\n",
      "0\n",
      "Best ELBO Loss : 0.001308503502755366\n",
      "Best NLL Loss : 1.7297641334202513e-06\n",
      "Best MSE Loss : 6.919056533681005e-07\n",
      "1\n",
      "Best ELBO Loss : 0.0013561612548008517\n",
      "Best NLL Loss : 2.4645492625378605e-06\n",
      "Best MSE Loss : 9.85819705015144e-07\n",
      "2\n",
      "Best ELBO Loss : 0.0011168933580275808\n",
      "Best NLL Loss : 1.698547060334334e-06\n",
      "Best MSE Loss : 6.794188241337336e-07\n",
      "3\n",
      "Best ELBO Loss : 0.0017664150024626357\n",
      "Best NLL Loss : 3.976782646545424e-06\n",
      "Best MSE Loss : 1.5907130586181695e-06\n",
      "4\n",
      "Best ELBO Loss : 0.001883202653846797\n",
      "Best NLL Loss : 3.110236205423923e-06\n",
      "Best MSE Loss : 1.2440944821695694e-06\n",
      "5\n",
      "Best ELBO Loss : 0.0028288609714020255\n",
      "Best NLL Loss : 8.083820925237912e-06\n",
      "Best MSE Loss : 3.233528370095165e-06\n",
      "6\n",
      "Best ELBO Loss : 0.00281993027726074\n",
      "Best NLL Loss : 1.723868242466639e-06\n",
      "Best MSE Loss : 6.895472969866556e-07\n",
      "7\n",
      "Best ELBO Loss : 0.0028310909089489847\n",
      "Best NLL Loss : 9.70247058327074e-06\n",
      "Best MSE Loss : 3.880988233308296e-06\n",
      "8\n",
      "Best ELBO Loss : 0.0025242620539426275\n",
      "Best NLL Loss : 7.034225496721485e-06\n",
      "Best MSE Loss : 2.8136901986885942e-06\n",
      "9\n",
      "6\n",
      "384097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ELBO Loss : 0.0006676565396630926\n",
      "Best NLL Loss : 1.2785236895266e-06\n",
      "Best MSE Loss : 5.114094758106399e-07\n",
      "0\n",
      "Best ELBO Loss : 0.0016706603561496007\n",
      "Best NLL Loss : 4.73421772833831e-06\n",
      "Best MSE Loss : 1.893687091335324e-06\n",
      "1\n",
      "Best ELBO Loss : 0.0017054468217565127\n",
      "Best NLL Loss : 3.582778345981719e-06\n",
      "Best MSE Loss : 1.4331113383926874e-06\n",
      "2\n",
      "Best ELBO Loss : 0.0013323783938137784\n",
      "Best NLL Loss : 1.1331845699666688e-06\n",
      "Best MSE Loss : 4.532738279866676e-07\n",
      "3\n",
      "Best ELBO Loss : 0.0017955664403977582\n",
      "Best NLL Loss : 1.8851550357302432e-06\n",
      "Best MSE Loss : 7.540620142920973e-07\n",
      "4\n",
      "Best ELBO Loss : 0.0022377966435256696\n",
      "Best NLL Loss : 4.284802031932866e-06\n",
      "Best MSE Loss : 1.7139208127731464e-06\n",
      "5\n",
      "Best ELBO Loss : 0.004530156035268575\n",
      "Best NLL Loss : 1.5138406074474566e-05\n",
      "Best MSE Loss : 6.0553624297898265e-06\n",
      "6\n",
      "Best ELBO Loss : 0.0069905977526850726\n",
      "Best NLL Loss : 1.9228406841653682e-05\n",
      "Best MSE Loss : 7.691362736661471e-06\n",
      "7\n",
      "Best ELBO Loss : 0.007181199385512972\n",
      "Best NLL Loss : 1.9058557299559493e-05\n",
      "Best MSE Loss : 7.623422919823797e-06\n",
      "8\n",
      "Best ELBO Loss : 0.006442484687111175\n",
      "Best NLL Loss : 1.9847086875360623e-05\n",
      "Best MSE Loss : 7.938834750144249e-06\n",
      "9\n",
      "7\n",
      "134030\n",
      "Best ELBO Loss : 0.0016765749064321807\n",
      "Best NLL Loss : 3.728310197301124e-06\n",
      "Best MSE Loss : 1.4913240789204494e-06\n",
      "0\n",
      "Best ELBO Loss : 0.002225597721451474\n",
      "Best NLL Loss : 4.530212510039762e-06\n",
      "Best MSE Loss : 1.8120850040159047e-06\n",
      "1\n",
      "Best ELBO Loss : 0.0025813359203902425\n",
      "Best NLL Loss : 4.638667264894901e-06\n",
      "Best MSE Loss : 1.8554669059579601e-06\n",
      "2\n",
      "Best ELBO Loss : 0.003227271117828648\n",
      "Best NLL Loss : 5.9989568090298045e-06\n",
      "Best MSE Loss : 2.3995827236119216e-06\n",
      "3\n",
      "Best ELBO Loss : 0.0033315790509163175\n",
      "Best NLL Loss : 1.6628632358064055e-05\n",
      "Best MSE Loss : 6.651452943225622e-06\n",
      "4\n",
      "Best ELBO Loss : 0.005271571122863201\n",
      "Best NLL Loss : 4.295354166157404e-06\n",
      "Best MSE Loss : 1.7181416664629616e-06\n",
      "5\n",
      "Best ELBO Loss : 0.004487243687080282\n",
      "Best NLL Loss : 1.5185109182485731e-05\n",
      "Best MSE Loss : 6.074043672994294e-06\n",
      "6\n",
      "Best ELBO Loss : 0.0037090481915808943\n",
      "Best NLL Loss : 9.926840591253426e-06\n",
      "Best MSE Loss : 3.97073623650137e-06\n",
      "7\n",
      "Best ELBO Loss : 0.006250137116580515\n",
      "Best NLL Loss : 8.943543181395513e-06\n",
      "Best MSE Loss : 3.577417272558205e-06\n",
      "8\n",
      "Best ELBO Loss : 0.00480604519302533\n",
      "Best NLL Loss : 1.432586686618703e-05\n",
      "Best MSE Loss : 5.730346746474812e-06\n",
      "9\n",
      "8\n",
      "454991\n",
      "Best ELBO Loss : 0.001028968187577436\n",
      "Best NLL Loss : 1.369463872913679e-06\n",
      "Best MSE Loss : 5.477855491654717e-07\n",
      "0\n",
      "Best ELBO Loss : 0.0014124385457612643\n",
      "Best NLL Loss : 1.6930000632258455e-06\n",
      "Best MSE Loss : 6.772000252903383e-07\n",
      "1\n",
      "Best ELBO Loss : 0.001509494275237026\n",
      "Best NLL Loss : 1.997804153121858e-06\n",
      "Best MSE Loss : 7.991216612487432e-07\n",
      "2\n",
      "Best ELBO Loss : 0.0012873724748973098\n",
      "Best NLL Loss : 1.6791200377096106e-06\n",
      "Best MSE Loss : 6.716480150838443e-07\n",
      "3\n",
      "Best ELBO Loss : 0.0018091694920219516\n",
      "Best NLL Loss : 3.051899716089951e-06\n",
      "Best MSE Loss : 1.2207598864359806e-06\n",
      "4\n",
      "Best ELBO Loss : 0.0019230092134069996\n",
      "Best NLL Loss : 5.028719149780303e-06\n",
      "Best MSE Loss : 2.0114876599121214e-06\n",
      "5\n",
      "Best ELBO Loss : 0.002794665187201198\n",
      "Best NLL Loss : 4.595495758174985e-06\n",
      "Best MSE Loss : 1.8381983032699942e-06\n",
      "6\n",
      "Best ELBO Loss : 0.0029326371169922983\n",
      "Best NLL Loss : 4.530529034095955e-06\n",
      "Best MSE Loss : 1.8122116136383817e-06\n",
      "7\n",
      "Best ELBO Loss : 0.0032692084993053965\n",
      "Best NLL Loss : 6.1280880455679334e-06\n",
      "Best MSE Loss : 2.4512352182271734e-06\n",
      "8\n",
      "Best ELBO Loss : 0.0033527645666123706\n",
      "Best NLL Loss : 1.4365291554097394e-05\n",
      "Best MSE Loss : 5.746116621638957e-06\n",
      "9\n",
      "9\n",
      "401627\n",
      "Best ELBO Loss : 0.00067255866066762\n",
      "Best NLL Loss : 9.70220662043238e-07\n",
      "Best MSE Loss : 3.880882648172952e-07\n",
      "0\n",
      "Best ELBO Loss : 0.0015128549920502248\n",
      "Best NLL Loss : 2.240688995091311e-06\n",
      "Best MSE Loss : 8.962755980365244e-07\n",
      "1\n",
      "Best ELBO Loss : 0.0009970099983213564\n",
      "Best NLL Loss : 1.2440016008210957e-06\n",
      "Best MSE Loss : 4.976006403284383e-07\n",
      "2\n",
      "Best ELBO Loss : 0.0013110125914749663\n",
      "Best NLL Loss : 1.4583411985035313e-06\n",
      "Best MSE Loss : 5.833364794014126e-07\n",
      "3\n",
      "Best ELBO Loss : 0.002177043357680224\n",
      "Best NLL Loss : 1.671808379440445e-06\n",
      "Best MSE Loss : 6.687233517761781e-07\n",
      "4\n",
      "Best ELBO Loss : 0.0023955361593444384\n",
      "Best NLL Loss : 1.2325028267670072e-05\n",
      "Best MSE Loss : 4.9300113070680285e-06\n",
      "5\n",
      "Best ELBO Loss : 0.0028142965498192834\n",
      "Best NLL Loss : 0.00011173905420720748\n",
      "Best MSE Loss : 4.4695621682883e-05\n",
      "6\n",
      "Best ELBO Loss : 0.005622168212436232\n",
      "Best NLL Loss : 0.002647753680542386\n",
      "Best MSE Loss : 0.0010591014722169544\n",
      "7\n",
      "Best ELBO Loss : 0.0034406111206081694\n",
      "Best NLL Loss : 9.79020524112335e-06\n",
      "Best MSE Loss : 3.91608209644934e-06\n",
      "8\n",
      "Best ELBO Loss : 0.019342025924971085\n",
      "Best NLL Loss : 0.015257773212385313\n",
      "Best MSE Loss : 0.006103109284954125\n",
      "9\n",
      "10\n",
      "97188\n",
      "Best ELBO Loss : 0.0010709297363402951\n",
      "Best NLL Loss : 1.8011128234426965e-06\n",
      "Best MSE Loss : 7.204451293770787e-07\n",
      "0\n",
      "Best ELBO Loss : 0.0011662016623108346\n",
      "Best NLL Loss : 1.8393647254357728e-06\n",
      "Best MSE Loss : 7.357458901743091e-07\n",
      "1\n",
      "Best ELBO Loss : 0.0010043593022895014\n",
      "Best NLL Loss : 1.3464147828402637e-06\n",
      "Best MSE Loss : 5.385659131361055e-07\n",
      "2\n",
      "Best ELBO Loss : 0.0015426378992541609\n",
      "Best NLL Loss : 2.7027294551852662e-06\n",
      "Best MSE Loss : 1.0810917820741064e-06\n",
      "3\n",
      "Best ELBO Loss : 0.0023029157277588415\n",
      "Best NLL Loss : 6.6981115407381556e-06\n",
      "Best MSE Loss : 2.6792446162952623e-06\n",
      "4\n",
      "Best ELBO Loss : 0.002832714904136254\n",
      "Best NLL Loss : 4.9192832293601115e-06\n",
      "Best MSE Loss : 1.9677132917440446e-06\n",
      "5\n",
      "Best ELBO Loss : 0.005198035173275811\n",
      "Best NLL Loss : 1.9572234343223542e-05\n",
      "Best MSE Loss : 7.828893737289417e-06\n",
      "6\n",
      "Best ELBO Loss : 0.005194881747077486\n",
      "Best NLL Loss : 1.032281807757915e-05\n",
      "Best MSE Loss : 4.129127231031659e-06\n",
      "7\n",
      "Best ELBO Loss : 0.005138293121688298\n",
      "Best NLL Loss : 2.765288577493287e-05\n",
      "Best MSE Loss : 1.1061154309973148e-05\n",
      "8\n",
      "Best ELBO Loss : 0.006694964761532985\n",
      "Best NLL Loss : 1.6660594289950106e-05\n",
      "Best MSE Loss : 6.664237715980042e-06\n",
      "9\n",
      "11\n",
      "615884\n",
      "Best ELBO Loss : 0.0013643781711924095\n",
      "Best NLL Loss : 3.225778997319517e-06\n",
      "Best MSE Loss : 1.2903115989278067e-06\n",
      "0\n",
      "Best ELBO Loss : 0.002294708870729081\n",
      "Best NLL Loss : 3.975446660650555e-06\n",
      "Best MSE Loss : 1.5901786642602216e-06\n",
      "1\n",
      "Best ELBO Loss : 0.002310314022777373\n",
      "Best NLL Loss : 9.167098834688091e-06\n",
      "Best MSE Loss : 3.6668395338752357e-06\n",
      "2\n",
      "Best ELBO Loss : 0.0023672279373603408\n",
      "Best NLL Loss : 7.606271746534872e-06\n",
      "Best MSE Loss : 3.0425086986139486e-06\n",
      "3\n",
      "Best ELBO Loss : 0.003473072768192274\n",
      "Best NLL Loss : 1.4166125474401827e-06\n",
      "Best MSE Loss : 5.666450189760731e-07\n",
      "4\n",
      "Best ELBO Loss : 0.003989822694507569\n",
      "Best NLL Loss : 6.881401779534552e-06\n",
      "Best MSE Loss : 2.7525607118138204e-06\n",
      "5\n",
      "Best ELBO Loss : 0.004590239629114867\n",
      "Best NLL Loss : 1.688963796271451e-05\n",
      "Best MSE Loss : 6.755855185085804e-06\n",
      "6\n",
      "Best ELBO Loss : 0.004781692588087917\n",
      "Best NLL Loss : 7.324583735178788e-06\n",
      "Best MSE Loss : 2.929833494071515e-06\n",
      "7\n",
      "Best ELBO Loss : 0.005077765705390509\n",
      "Best NLL Loss : 9.122787005459927e-06\n",
      "Best MSE Loss : 3.649114802183971e-06\n",
      "8\n",
      "Best ELBO Loss : 0.004825382648799381\n",
      "Best NLL Loss : 1.716734726273963e-05\n",
      "Best MSE Loss : 6.866938905095853e-06\n",
      "9\n",
      "12\n",
      "585262\n",
      "Best ELBO Loss : 0.0009258718813437837\n",
      "Best NLL Loss : 1.2966874503105668e-06\n",
      "Best MSE Loss : 5.186749801242267e-07\n",
      "0\n",
      "Best ELBO Loss : 0.0011765108897832974\n",
      "Best NLL Loss : 1.2243365995579082e-06\n",
      "Best MSE Loss : 4.897346398231633e-07\n",
      "1\n",
      "Best ELBO Loss : 0.0016683233204208452\n",
      "Best NLL Loss : 2.5429391930468058e-06\n",
      "Best MSE Loss : 1.0171756772187225e-06\n",
      "2\n",
      "Best ELBO Loss : 0.0020842789936589344\n",
      "Best NLL Loss : 3.0546340634903926e-06\n",
      "Best MSE Loss : 1.221853625396157e-06\n",
      "3\n",
      "Best ELBO Loss : 0.0020505380332967596\n",
      "Best NLL Loss : 4.464097959998922e-06\n",
      "Best MSE Loss : 1.7856391839995688e-06\n",
      "4\n",
      "Best ELBO Loss : 0.0029391866504822907\n",
      "Best NLL Loss : 6.019930476085475e-06\n",
      "Best MSE Loss : 2.40797219043419e-06\n",
      "5\n",
      "Best ELBO Loss : 0.0027605036556501454\n",
      "Best NLL Loss : 6.6269213459802025e-06\n",
      "Best MSE Loss : 2.650768538392081e-06\n",
      "6\n",
      "Best ELBO Loss : 0.004207648977245504\n",
      "Best NLL Loss : 1.686989785853817e-05\n",
      "Best MSE Loss : 6.747959143415269e-06\n",
      "7\n",
      "Best ELBO Loss : 0.003987234196064084\n",
      "Best NLL Loss : 1.3503073340096468e-05\n",
      "Best MSE Loss : 5.401229336038587e-06\n",
      "8\n",
      "Best ELBO Loss : 0.004681379890979531\n",
      "Best NLL Loss : 1.3614025342663207e-05\n",
      "Best MSE Loss : 5.445610137065283e-06\n",
      "9\n",
      "13\n",
      "902641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ELBO Loss : 0.0008664561473829464\n",
      "Best NLL Loss : 1.1830912748589285e-06\n",
      "Best MSE Loss : 4.732365099435714e-07\n",
      "0\n",
      "Best ELBO Loss : 0.0015596474395025\n",
      "Best NLL Loss : 3.004044508887761e-06\n",
      "Best MSE Loss : 1.2016178035551045e-06\n",
      "1\n",
      "Best ELBO Loss : 0.0017130510332415481\n",
      "Best NLL Loss : 3.306962250728766e-06\n",
      "Best MSE Loss : 1.3227849002915065e-06\n",
      "2\n",
      "Best ELBO Loss : 0.0018138998997825999\n",
      "Best NLL Loss : 3.1656020237323147e-06\n",
      "Best MSE Loss : 1.266240809492926e-06\n",
      "3\n",
      "Best ELBO Loss : 0.0023649716499709672\n",
      "Best NLL Loss : 9.959169660234947e-06\n",
      "Best MSE Loss : 3.983667864093978e-06\n",
      "4\n",
      "Best ELBO Loss : 0.002505475089688279\n",
      "Best NLL Loss : 1.4468741615052503e-05\n",
      "Best MSE Loss : 5.787496646021001e-06\n",
      "5\n",
      "Best ELBO Loss : 0.003081308495635063\n",
      "Best NLL Loss : 5.720695973485139e-06\n",
      "Best MSE Loss : 2.288278389394056e-06\n",
      "6\n",
      "Best ELBO Loss : 0.002664413666551569\n",
      "Best NLL Loss : 3.869743914737332e-06\n",
      "Best MSE Loss : 1.547897565894933e-06\n",
      "7\n",
      "Best ELBO Loss : 0.0031934951793291537\n",
      "Best NLL Loss : 1.1111544522406409e-05\n",
      "Best MSE Loss : 4.444617808962563e-06\n",
      "8\n",
      "Best ELBO Loss : 0.0034367008611316838\n",
      "Best NLL Loss : 9.851292440382199e-06\n",
      "Best MSE Loss : 3.94051697615288e-06\n",
      "9\n",
      "14\n",
      "897795\n",
      "Best ELBO Loss : 0.0010140326421486953\n",
      "Best NLL Loss : 6.963426033248609e-07\n",
      "Best MSE Loss : 2.785370413299444e-07\n",
      "0\n",
      "Best ELBO Loss : 0.0012476680469533223\n",
      "Best NLL Loss : 1.2515432253402235e-06\n",
      "Best MSE Loss : 5.006172901360894e-07\n",
      "1\n",
      "Best ELBO Loss : 0.001721333184616932\n",
      "Best NLL Loss : 2.2084652627680133e-06\n",
      "Best MSE Loss : 8.833861051072054e-07\n",
      "2\n",
      "Best ELBO Loss : 0.001616461710888324\n",
      "Best NLL Loss : 2.5058223613045536e-06\n",
      "Best MSE Loss : 1.0023289445218213e-06\n",
      "3\n",
      "Best ELBO Loss : 0.0018963232153187438\n",
      "Best NLL Loss : 4.211278395888564e-06\n",
      "Best MSE Loss : 1.6845113583554257e-06\n",
      "4\n",
      "Best ELBO Loss : 0.002508399626346356\n",
      "Best NLL Loss : 9.69022681959651e-06\n",
      "Best MSE Loss : 3.876090727838604e-06\n",
      "5\n",
      "Best ELBO Loss : 0.002824768680944717\n",
      "Best NLL Loss : 8.690528640732231e-06\n",
      "Best MSE Loss : 3.476211456292892e-06\n",
      "6\n",
      "Best ELBO Loss : 0.0022839521170465163\n",
      "Best NLL Loss : 6.828606345793558e-06\n",
      "Best MSE Loss : 2.7314425383174232e-06\n",
      "7\n",
      "Best ELBO Loss : 0.0033509651348744255\n",
      "Best NLL Loss : 1.1505655346053168e-05\n",
      "Best MSE Loss : 4.602262138421267e-06\n",
      "8\n",
      "Best ELBO Loss : 0.0038210107621284603\n",
      "Best NLL Loss : 6.682904715238254e-06\n",
      "Best MSE Loss : 2.6731618860953015e-06\n",
      "9\n",
      "15\n",
      "678150\n",
      "Best ELBO Loss : 0.0008566875047716683\n",
      "Best NLL Loss : 1.0323226498339678e-06\n",
      "Best MSE Loss : 4.129290599335872e-07\n",
      "0\n",
      "Best ELBO Loss : 0.0010559185367341594\n",
      "Best NLL Loss : 1.3985969643564425e-06\n",
      "Best MSE Loss : 5.59438785742577e-07\n",
      "1\n",
      "Best ELBO Loss : 0.0014088140509945465\n",
      "Best NLL Loss : 1.967471168938893e-06\n",
      "Best MSE Loss : 7.869884675755572e-07\n",
      "2\n",
      "Best ELBO Loss : 0.0013148145835071275\n",
      "Best NLL Loss : 1.0370294574565738e-06\n",
      "Best MSE Loss : 4.1481178298262963e-07\n",
      "3\n",
      "Best ELBO Loss : 0.0019404059987325575\n",
      "Best NLL Loss : 6.7683817509550825e-06\n",
      "Best MSE Loss : 2.7073527003820327e-06\n",
      "4\n",
      "Best ELBO Loss : 0.0018023364543110151\n",
      "Best NLL Loss : 4.252761204673035e-06\n",
      "Best MSE Loss : 1.7011044818692142e-06\n",
      "5\n",
      "Best ELBO Loss : 0.002442098731689398\n",
      "Best NLL Loss : 4.555281625910583e-06\n",
      "Best MSE Loss : 1.8221126503642333e-06\n",
      "6\n",
      "Best ELBO Loss : 0.003328977914468247\n",
      "Best NLL Loss : 4.052158455437533e-06\n",
      "Best MSE Loss : 1.6208633821750133e-06\n",
      "7\n",
      "Best ELBO Loss : 0.004230717658663918\n",
      "Best NLL Loss : 8.234601795673333e-06\n",
      "Best MSE Loss : 3.2938407182693334e-06\n",
      "8\n",
      "Best ELBO Loss : 0.0038194920082096663\n",
      "Best NLL Loss : 4.013968385048208e-06\n",
      "Best MSE Loss : 1.605587354019283e-06\n",
      "9\n",
      "16\n",
      "361884\n",
      "Best ELBO Loss : 0.0009368042172219365\n",
      "Best NLL Loss : 2.184657606667076e-06\n",
      "Best MSE Loss : 8.738630426668304e-07\n",
      "0\n",
      "Best ELBO Loss : 0.001205661530512385\n",
      "Best NLL Loss : 1.2635451151007985e-06\n",
      "Best MSE Loss : 5.054180460403194e-07\n",
      "1\n",
      "Best ELBO Loss : 0.001305241399086181\n",
      "Best NLL Loss : 1.59235258444715e-06\n",
      "Best MSE Loss : 6.369410337788599e-07\n",
      "2\n",
      "Best ELBO Loss : 0.0017384261947914772\n",
      "Best NLL Loss : 3.925968198570536e-06\n",
      "Best MSE Loss : 1.5703872794282145e-06\n",
      "3\n",
      "Best ELBO Loss : 0.002464650302787714\n",
      "Best NLL Loss : 4.095431893220948e-06\n",
      "Best MSE Loss : 1.6381727572883791e-06\n",
      "4\n",
      "Best ELBO Loss : 0.002344258585387989\n",
      "Best NLL Loss : 2.0497936719958684e-06\n",
      "Best MSE Loss : 8.199174687983474e-07\n",
      "5\n",
      "Best ELBO Loss : 0.0026442604116936486\n",
      "Best NLL Loss : 4.095162347108851e-06\n",
      "Best MSE Loss : 1.6380649388435405e-06\n",
      "6\n",
      "Best ELBO Loss : 0.003923881276306802\n",
      "Best NLL Loss : 4.013325816281775e-06\n",
      "Best MSE Loss : 1.60533032651271e-06\n",
      "7\n",
      "Best ELBO Loss : 0.005173617504561683\n",
      "Best NLL Loss : 1.2633872721806483e-05\n",
      "Best MSE Loss : 5.053549088722593e-06\n",
      "8\n",
      "Best ELBO Loss : 0.003387390336312792\n",
      "Best NLL Loss : 4.647612662975388e-06\n",
      "Best MSE Loss : 1.859045065190155e-06\n",
      "9\n",
      "17\n",
      "928159\n",
      "Best ELBO Loss : 0.0007999821012849558\n",
      "Best NLL Loss : 5.38677988146574e-07\n",
      "Best MSE Loss : 2.1547119525862963e-07\n",
      "0\n",
      "Best ELBO Loss : 0.0020379888197679134\n",
      "Best NLL Loss : 3.5664158155448016e-06\n",
      "Best MSE Loss : 1.4265663262179207e-06\n",
      "1\n",
      "Best ELBO Loss : 0.0013921280917783827\n",
      "Best NLL Loss : 1.5889728330350102e-06\n",
      "Best MSE Loss : 6.355891332140041e-07\n",
      "2\n",
      "Best ELBO Loss : 0.0015123600468228196\n",
      "Best NLL Loss : 1.6001929941216262e-06\n",
      "Best MSE Loss : 6.400771976486504e-07\n",
      "3\n",
      "Best ELBO Loss : 0.002074681382977205\n",
      "Best NLL Loss : 2.6007813699021636e-06\n",
      "Best MSE Loss : 1.0403125479608656e-06\n",
      "4\n",
      "Best ELBO Loss : 0.0028862684602398146\n",
      "Best NLL Loss : 3.6266915375167024e-06\n",
      "Best MSE Loss : 1.450676615006681e-06\n",
      "5\n",
      "Best ELBO Loss : 0.0028618384990584484\n",
      "Best NLL Loss : 5.112776944898722e-06\n",
      "Best MSE Loss : 2.045110777959489e-06\n",
      "6\n",
      "Best ELBO Loss : 0.0025575915686516966\n",
      "Best NLL Loss : 2.555533907900343e-06\n",
      "Best MSE Loss : 1.0222135631601372e-06\n",
      "7\n",
      "Best ELBO Loss : 0.0022690871023336306\n",
      "Best NLL Loss : 6.827187684501921e-06\n",
      "Best MSE Loss : 2.7308750738007685e-06\n",
      "8\n",
      "Best ELBO Loss : 0.0025513700885779057\n",
      "Best NLL Loss : 3.671107597619473e-06\n",
      "Best MSE Loss : 1.4684430390477895e-06\n",
      "9\n",
      "18\n",
      "446640\n",
      "Best ELBO Loss : 0.0011274114107915458\n",
      "Best NLL Loss : 3.000790586185535e-06\n",
      "Best MSE Loss : 1.2003162344742137e-06\n",
      "0\n",
      "Best ELBO Loss : 0.0016552883825174378\n",
      "Best NLL Loss : 5.753072408807676e-05\n",
      "Best MSE Loss : 2.3012289635230702e-05\n",
      "1\n",
      "Best ELBO Loss : 0.0014633985106154174\n",
      "Best NLL Loss : 7.231103370013628e-07\n",
      "Best MSE Loss : 2.892441348005451e-07\n",
      "2\n",
      "Best ELBO Loss : 0.0013401843498695467\n",
      "Best NLL Loss : 2.563815246924423e-06\n",
      "Best MSE Loss : 1.0255260987697693e-06\n",
      "3\n",
      "Best ELBO Loss : 0.0022988489602948836\n",
      "Best NLL Loss : 2.3631901910906573e-06\n",
      "Best MSE Loss : 9.452760764362627e-07\n",
      "4\n",
      "Best ELBO Loss : 0.0022979990601280555\n",
      "Best NLL Loss : 2.9249903215720584e-06\n",
      "Best MSE Loss : 1.1699961286288232e-06\n",
      "5\n",
      "Best ELBO Loss : 0.00209667089455674\n",
      "Best NLL Loss : 2.4339374881710657e-06\n",
      "Best MSE Loss : 9.735749952684261e-07\n",
      "6\n",
      "Best ELBO Loss : 0.003274588477166312\n",
      "Best NLL Loss : 4.38750786363771e-06\n",
      "Best MSE Loss : 1.755003145455084e-06\n",
      "7\n",
      "Best ELBO Loss : 0.0029255336914254418\n",
      "Best NLL Loss : 3.1789718325417803e-06\n",
      "Best MSE Loss : 1.271588733016712e-06\n",
      "8\n",
      "Best ELBO Loss : 0.002837033709798276\n",
      "Best NLL Loss : 7.158232110711454e-06\n",
      "Best MSE Loss : 2.8632928442845815e-06\n",
      "9\n",
      "19\n",
      "26580\n",
      "Best ELBO Loss : 0.0011744692433878123\n",
      "Best NLL Loss : 3.659814548190354e-06\n",
      "Best MSE Loss : 1.4639258192761415e-06\n",
      "0\n",
      "Best ELBO Loss : 0.001065851939558403\n",
      "Best NLL Loss : 1.3405713392419148e-06\n",
      "Best MSE Loss : 5.362285356967659e-07\n",
      "1\n",
      "Best ELBO Loss : 0.0012312862041821372\n",
      "Best NLL Loss : 1.4909076419788879e-06\n",
      "Best MSE Loss : 5.963630567915553e-07\n",
      "2\n",
      "Best ELBO Loss : 0.001693741128569257\n",
      "Best NLL Loss : 2.1693535319064257e-06\n",
      "Best MSE Loss : 8.677414127625703e-07\n",
      "3\n",
      "Best ELBO Loss : 0.00172253568393485\n",
      "Best NLL Loss : 1.1824167789871267e-06\n",
      "Best MSE Loss : 4.7296671159485066e-07\n",
      "4\n",
      "Best ELBO Loss : 0.0019929968719018514\n",
      "Best NLL Loss : 2.1518782859170953e-06\n",
      "Best MSE Loss : 8.607513143668382e-07\n",
      "5\n",
      "Best ELBO Loss : 0.002146015483112468\n",
      "Best NLL Loss : 1.3519701611763216e-06\n",
      "Best MSE Loss : 5.407880644705287e-07\n",
      "6\n",
      "Best ELBO Loss : 0.00256981491862871\n",
      "Best NLL Loss : 1.4795237720492525e-06\n",
      "Best MSE Loss : 5.91809508819701e-07\n",
      "7\n",
      "Best ELBO Loss : 0.0026163317470451895\n",
      "Best NLL Loss : 1.7315162738031208e-06\n",
      "Best MSE Loss : 6.926065095212482e-07\n",
      "8\n",
      "Best ELBO Loss : 0.0027610975827671337\n",
      "Best NLL Loss : 5.427910118548895e-06\n",
      "Best MSE Loss : 2.171164047419558e-06\n",
      "9\n",
      "20\n",
      "865407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ELBO Loss : 0.0007557301875587557\n",
      "Best NLL Loss : 1.3921503771967917e-06\n",
      "Best MSE Loss : 5.568601508787167e-07\n",
      "0\n",
      "Best ELBO Loss : 0.001488766066591578\n",
      "Best NLL Loss : 2.5109327695811647e-06\n",
      "Best MSE Loss : 1.004373107832466e-06\n",
      "1\n",
      "Best ELBO Loss : 0.0013816856885100184\n",
      "Best NLL Loss : 1.0733924675219174e-06\n",
      "Best MSE Loss : 4.29356987008767e-07\n",
      "2\n",
      "Best ELBO Loss : 0.0017844531519652278\n",
      "Best NLL Loss : 1.8296856265207118e-06\n",
      "Best MSE Loss : 7.318742506082847e-07\n",
      "3\n",
      "Best ELBO Loss : 0.0019479072698609632\n",
      "Best NLL Loss : 5.436117273306184e-06\n",
      "Best MSE Loss : 2.174446909322474e-06\n",
      "4\n",
      "Best ELBO Loss : 0.0027885221946829203\n",
      "Best NLL Loss : 1.3377499028537296e-05\n",
      "Best MSE Loss : 5.350999611414919e-06\n",
      "5\n",
      "Best ELBO Loss : 0.0023871201697042155\n",
      "Best NLL Loss : 9.620312255483512e-06\n",
      "Best MSE Loss : 3.848124902193404e-06\n",
      "6\n",
      "Best ELBO Loss : 0.002929237051260788\n",
      "Best NLL Loss : 1.607778435208608e-05\n",
      "Best MSE Loss : 6.431113740834432e-06\n",
      "7\n",
      "Best ELBO Loss : 0.0035272219566456296\n",
      "Best NLL Loss : 7.374995376004077e-06\n",
      "Best MSE Loss : 2.9499981504016312e-06\n",
      "8\n",
      "Best ELBO Loss : 0.002973468153802064\n",
      "Best NLL Loss : 5.333654234970651e-06\n",
      "Best MSE Loss : 2.1334616939882607e-06\n",
      "9\n",
      "21\n",
      "789523\n",
      "Best ELBO Loss : 0.0010565143801006625\n",
      "Best NLL Loss : 1.9500620564437205e-06\n",
      "Best MSE Loss : 7.800248225774882e-07\n",
      "0\n",
      "Best ELBO Loss : 0.0021246950375163566\n",
      "Best NLL Loss : 5.444515226690641e-06\n",
      "Best MSE Loss : 2.1778060906762567e-06\n",
      "1\n",
      "Best ELBO Loss : 0.0017254920633329746\n",
      "Best NLL Loss : 1.7148055563705834e-06\n",
      "Best MSE Loss : 6.859222225482335e-07\n",
      "2\n",
      "Best ELBO Loss : 0.003547273177859175\n",
      "Best NLL Loss : 7.892986359559646e-06\n",
      "Best MSE Loss : 3.157194543823859e-06\n",
      "3\n",
      "Best ELBO Loss : 0.003906106833059473\n",
      "Best NLL Loss : 2.6442457532497043e-05\n",
      "Best MSE Loss : 1.0576983012998817e-05\n",
      "4\n",
      "Best ELBO Loss : 0.0054719260625362715\n",
      "Best NLL Loss : 3.9656319189356316e-05\n",
      "Best MSE Loss : 1.5862527675742526e-05\n",
      "5\n",
      "Best ELBO Loss : 0.009254621122670675\n",
      "Best NLL Loss : 0.0002136648706966527\n",
      "Best MSE Loss : 8.54659482786611e-05\n",
      "6\n",
      "Best ELBO Loss : 0.012903897940813265\n",
      "Best NLL Loss : 0.00013462770364469816\n",
      "Best MSE Loss : 5.3851081457879264e-05\n",
      "7\n",
      "Best ELBO Loss : 0.011614238160080236\n",
      "Best NLL Loss : 0.00024744587699934326\n",
      "Best MSE Loss : 9.897835079973731e-05\n",
      "8\n",
      "Best ELBO Loss : 0.013421638867125456\n",
      "Best NLL Loss : 0.000269871700467755\n",
      "Best MSE Loss : 0.00010794868018710201\n",
      "9\n",
      "22\n",
      "704840\n",
      "Best ELBO Loss : 0.0010240957668404937\n",
      "Best NLL Loss : 2.203019232818643e-06\n",
      "Best MSE Loss : 8.812076931274573e-07\n",
      "0\n",
      "Best ELBO Loss : 0.001173918976069354\n",
      "Best NLL Loss : 1.7740120124555718e-06\n",
      "Best MSE Loss : 7.096048049822287e-07\n",
      "1\n",
      "Best ELBO Loss : 0.0015409524922408552\n",
      "Best NLL Loss : 1.9094026751241026e-06\n",
      "Best MSE Loss : 7.63761070049641e-07\n",
      "2\n",
      "Best ELBO Loss : 0.0011880947004179459\n",
      "Best NLL Loss : 1.66424403555682e-06\n",
      "Best MSE Loss : 6.65697614222728e-07\n",
      "3\n",
      "Best ELBO Loss : 0.002402197142046931\n",
      "Best NLL Loss : 3.4074502152391144e-06\n",
      "Best MSE Loss : 1.3629800860956458e-06\n",
      "4\n",
      "Best ELBO Loss : 0.002601823110625757\n",
      "Best NLL Loss : 4.376966513944856e-06\n",
      "Best MSE Loss : 1.7507866055779423e-06\n",
      "5\n",
      "Best ELBO Loss : 0.0036536208938767385\n",
      "Best NLL Loss : 6.112974674439158e-06\n",
      "Best MSE Loss : 2.445189869775663e-06\n",
      "6\n",
      "Best ELBO Loss : 0.0026337541369028648\n",
      "Best NLL Loss : 5.479053004528926e-06\n",
      "Best MSE Loss : 2.1916212018115703e-06\n",
      "7\n",
      "Best ELBO Loss : 0.002631293125811954\n",
      "Best NLL Loss : 3.6173037541623554e-06\n",
      "Best MSE Loss : 1.4469215016649423e-06\n",
      "8\n",
      "Best ELBO Loss : 0.003678676959864011\n",
      "Best NLL Loss : 7.219191373741448e-06\n",
      "Best MSE Loss : 2.887676549496579e-06\n",
      "9\n",
      "23\n",
      "359269\n",
      "Best ELBO Loss : 0.001386372535650848\n",
      "Best NLL Loss : 2.52460538804149e-06\n",
      "Best MSE Loss : 1.009842155216596e-06\n",
      "0\n",
      "Best ELBO Loss : 0.001990218157234024\n",
      "Best NLL Loss : 3.3937485320065383e-06\n",
      "Best MSE Loss : 1.3574994128026155e-06\n",
      "1\n",
      "Best ELBO Loss : 0.00187519370612586\n",
      "Best NLL Loss : 4.463365136919536e-06\n",
      "Best MSE Loss : 1.7853460547678143e-06\n",
      "2\n",
      "Best ELBO Loss : 0.002441366893903844\n",
      "Best NLL Loss : 8.690713204015285e-06\n",
      "Best MSE Loss : 3.4762852816061147e-06\n",
      "3\n",
      "Best ELBO Loss : 0.0031705396047403936\n",
      "Best NLL Loss : 1.2966834942878344e-05\n",
      "Best MSE Loss : 5.186733977151338e-06\n",
      "4\n",
      "Best ELBO Loss : 0.004643420616111715\n",
      "Best NLL Loss : 3.173840368123989e-05\n",
      "Best MSE Loss : 1.2695361472495956e-05\n",
      "5\n",
      "Best ELBO Loss : 0.006201202870363243\n",
      "Best NLL Loss : 3.539315451408826e-05\n",
      "Best MSE Loss : 1.4157261805635304e-05\n",
      "6\n",
      "Best ELBO Loss : 0.0057581465569993395\n",
      "Best NLL Loss : 2.5667519886870475e-05\n",
      "Best MSE Loss : 1.026700795474819e-05\n",
      "7\n",
      "Best ELBO Loss : 0.006691834980563178\n",
      "Best NLL Loss : 2.8896198642162658e-05\n",
      "Best MSE Loss : 1.1558479456865064e-05\n",
      "8\n",
      "Best ELBO Loss : 0.006046503041931651\n",
      "Best NLL Loss : 2.2789277027869162e-05\n",
      "Best MSE Loss : 9.115710811147665e-06\n",
      "9\n",
      "24\n",
      "38248\n",
      "Best ELBO Loss : 0.0008219350278051814\n",
      "Best NLL Loss : 1.0099630473320451e-06\n",
      "Best MSE Loss : 4.039852189328181e-07\n",
      "0\n",
      "Best ELBO Loss : 0.0012370161520985513\n",
      "Best NLL Loss : 2.261578654104524e-06\n",
      "Best MSE Loss : 9.046314616418094e-07\n",
      "1\n",
      "Best ELBO Loss : 0.0013588767883120146\n",
      "Best NLL Loss : 2.2653233336071384e-06\n",
      "Best MSE Loss : 9.061293334428555e-07\n",
      "2\n",
      "Best ELBO Loss : 0.0015675597840364769\n",
      "Best NLL Loss : 2.4166022892937273e-06\n",
      "Best MSE Loss : 9.66640915717491e-07\n",
      "3\n",
      "Best ELBO Loss : 0.002166060744047738\n",
      "Best NLL Loss : 6.8262164896059944e-06\n",
      "Best MSE Loss : 2.730486595842397e-06\n",
      "4\n",
      "Best ELBO Loss : 0.0029605991027567514\n",
      "Best NLL Loss : 1.1686517672475864e-05\n",
      "Best MSE Loss : 4.674607068990346e-06\n",
      "5\n",
      "Best ELBO Loss : 0.0030204703694393436\n",
      "Best NLL Loss : 8.836657429330076e-06\n",
      "Best MSE Loss : 3.5346629717320307e-06\n",
      "6\n",
      "Best ELBO Loss : 0.0037546906893161543\n",
      "Best NLL Loss : 1.155118601541226e-05\n",
      "Best MSE Loss : 4.6204744061649035e-06\n",
      "7\n",
      "Best ELBO Loss : 0.0044975750121833006\n",
      "Best NLL Loss : 1.5802993553527732e-05\n",
      "Best MSE Loss : 6.321197421411093e-06\n",
      "8\n",
      "Best ELBO Loss : 0.00395515944425388\n",
      "Best NLL Loss : 1.3062625465328547e-05\n",
      "Best MSE Loss : 5.2250501861314185e-06\n",
      "9\n",
      "25\n",
      "809111\n",
      "Best ELBO Loss : 0.0005041895758502901\n",
      "Best NLL Loss : 2.3177530757634136e-06\n",
      "Best MSE Loss : 9.271012303053655e-07\n",
      "0\n",
      "Best ELBO Loss : 0.0010318971112479815\n",
      "Best NLL Loss : 1.5790397201079865e-06\n",
      "Best MSE Loss : 6.316158880431946e-07\n",
      "1\n",
      "Best ELBO Loss : 0.0010171957979899083\n",
      "Best NLL Loss : 1.4095707551599714e-06\n",
      "Best MSE Loss : 5.638283020639886e-07\n",
      "2\n",
      "Best ELBO Loss : 0.0011012175512532696\n",
      "Best NLL Loss : 1.495491120204895e-06\n",
      "Best MSE Loss : 5.981964480819579e-07\n",
      "3\n",
      "Best ELBO Loss : 0.0013611444787613959\n",
      "Best NLL Loss : 1.7551214709894112e-06\n",
      "Best MSE Loss : 7.020485883957645e-07\n",
      "4\n",
      "Best ELBO Loss : 0.0017066968897187205\n",
      "Best NLL Loss : 1.6091211723743385e-06\n",
      "Best MSE Loss : 6.436484689497354e-07\n",
      "5\n",
      "Best ELBO Loss : 0.0018116761035602764\n",
      "Best NLL Loss : 2.033695576668366e-06\n",
      "Best MSE Loss : 8.134782306673464e-07\n",
      "6\n",
      "Best ELBO Loss : 0.0020758940263452303\n",
      "Best NLL Loss : 2.8000003559464988e-06\n",
      "Best MSE Loss : 1.1200001423785995e-06\n",
      "7\n",
      "Best ELBO Loss : 0.002458975842397163\n",
      "Best NLL Loss : 2.685797820676468e-06\n",
      "Best MSE Loss : 1.0743191282705872e-06\n",
      "8\n",
      "Best ELBO Loss : 0.0025218099033302442\n",
      "Best NLL Loss : 3.1836451195948397e-06\n",
      "Best MSE Loss : 1.2734580478379362e-06\n",
      "9\n",
      "26\n",
      "137636\n",
      "Best ELBO Loss : 0.0009963361960575784\n",
      "Best NLL Loss : 7.879999683356841e-07\n",
      "Best MSE Loss : 3.151999873342737e-07\n",
      "0\n",
      "Best ELBO Loss : 0.0017814046562857782\n",
      "Best NLL Loss : 2.080791097235002e-06\n",
      "Best MSE Loss : 8.323164388940007e-07\n",
      "1\n",
      "Best ELBO Loss : 0.0013076568609811225\n",
      "Best NLL Loss : 2.0381605643480525e-06\n",
      "Best MSE Loss : 8.15264225739221e-07\n",
      "2\n",
      "Best ELBO Loss : 0.0017718504242885031\n",
      "Best NLL Loss : 1.5762761929668242e-06\n",
      "Best MSE Loss : 6.305104771867297e-07\n",
      "3\n",
      "Best ELBO Loss : 0.001920377771551453\n",
      "Best NLL Loss : 7.3361444133313195e-06\n",
      "Best MSE Loss : 2.9344577653325274e-06\n",
      "4\n",
      "Best ELBO Loss : 0.0023227528137050235\n",
      "Best NLL Loss : 5.076484094391544e-06\n",
      "Best MSE Loss : 2.030593637756618e-06\n",
      "5\n",
      "Best ELBO Loss : 0.003143339574625508\n",
      "Best NLL Loss : 7.391642251121475e-06\n",
      "Best MSE Loss : 2.95665690044859e-06\n",
      "6\n",
      "Best ELBO Loss : 0.00406622729488404\n",
      "Best NLL Loss : 1.052584564425047e-05\n",
      "Best MSE Loss : 4.210338257700188e-06\n",
      "7\n",
      "Best ELBO Loss : 0.0038890832528281254\n",
      "Best NLL Loss : 5.619775714778837e-06\n",
      "Best MSE Loss : 2.247910285911535e-06\n",
      "8\n",
      "Best ELBO Loss : 0.003282652049256063\n",
      "Best NLL Loss : 7.406271221248608e-06\n",
      "Best MSE Loss : 2.962508488499443e-06\n",
      "9\n",
      "27\n",
      "698530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ELBO Loss : 0.0015360416481800087\n",
      "Best NLL Loss : 4.631643804578602e-06\n",
      "Best MSE Loss : 1.852657521831441e-06\n",
      "0\n",
      "Best ELBO Loss : 0.0028454900478387946\n",
      "Best NLL Loss : 7.4071769666193425e-06\n",
      "Best MSE Loss : 2.9628707866477373e-06\n",
      "1\n",
      "Best ELBO Loss : 0.002368789212971471\n",
      "Best NLL Loss : 4.107185819846282e-06\n",
      "Best MSE Loss : 1.6428743279385128e-06\n",
      "2\n",
      "Best ELBO Loss : 0.0036842892187553193\n",
      "Best NLL Loss : 8.025838262527404e-06\n",
      "Best MSE Loss : 3.2103353050109615e-06\n",
      "3\n",
      "Best ELBO Loss : 0.0036751240935715083\n",
      "Best NLL Loss : 6.848959453373274e-06\n",
      "Best MSE Loss : 2.73958378134931e-06\n",
      "4\n",
      "Best ELBO Loss : 0.005454305489732032\n",
      "Best NLL Loss : 2.0119515884412234e-05\n",
      "Best MSE Loss : 8.047806353764894e-06\n",
      "5\n",
      "Best ELBO Loss : 0.006125234212999026\n",
      "Best NLL Loss : 2.7108074473755422e-05\n",
      "Best MSE Loss : 1.0843229789502169e-05\n",
      "6\n",
      "Best ELBO Loss : 0.008550102535799117\n",
      "Best NLL Loss : 3.893814979118238e-05\n",
      "Best MSE Loss : 1.557525991647295e-05\n",
      "7\n",
      "Best ELBO Loss : 0.009066755513400143\n",
      "Best NLL Loss : 4.450955772739538e-05\n",
      "Best MSE Loss : 1.7803823090958152e-05\n",
      "8\n",
      "Best ELBO Loss : 0.008740164852539041\n",
      "Best NLL Loss : 3.200875115348486e-05\n",
      "Best MSE Loss : 1.2803500461393944e-05\n",
      "9\n",
      "28\n",
      "230177\n",
      "Best ELBO Loss : 0.0014936802371742198\n",
      "Best NLL Loss : 2.473239931222026e-06\n",
      "Best MSE Loss : 9.892959724888104e-07\n",
      "0\n",
      "Best ELBO Loss : 0.0023623256423097984\n",
      "Best NLL Loss : 2.8224139370123725e-06\n",
      "Best MSE Loss : 1.1289655748049491e-06\n",
      "1\n",
      "Best ELBO Loss : 0.001976689013027675\n",
      "Best NLL Loss : 3.532177944318131e-06\n",
      "Best MSE Loss : 1.4128711777272525e-06\n",
      "2\n",
      "Best ELBO Loss : 0.0020388461630327713\n",
      "Best NLL Loss : 3.4484707758033837e-06\n",
      "Best MSE Loss : 1.3793883103213533e-06\n",
      "3\n",
      "Best ELBO Loss : 0.0029142183203750742\n",
      "Best NLL Loss : 4.425947373037056e-06\n",
      "Best MSE Loss : 1.7703789492148224e-06\n",
      "4\n",
      "Best ELBO Loss : 0.0036170368329993346\n",
      "Best NLL Loss : 5.959613552625843e-06\n",
      "Best MSE Loss : 2.3838454210503373e-06\n",
      "5\n",
      "Best ELBO Loss : 0.0046501408611219356\n",
      "Best NLL Loss : 7.611324351457513e-06\n",
      "Best MSE Loss : 3.044529740583005e-06\n",
      "6\n",
      "Best ELBO Loss : 0.005627333722925916\n",
      "Best NLL Loss : 2.550565004547989e-05\n",
      "Best MSE Loss : 1.0202260018191955e-05\n",
      "7\n",
      "Best ELBO Loss : 0.007679036830385277\n",
      "Best NLL Loss : 1.4042042741575048e-05\n",
      "Best MSE Loss : 5.61681709663002e-06\n",
      "8\n",
      "Best ELBO Loss : 0.006523919932218953\n",
      "Best NLL Loss : 7.114217662475107e-06\n",
      "Best MSE Loss : 2.845687064990043e-06\n",
      "9\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "n = 30 # The number of samples of data.\n",
    "d = 5 # The number of variables in data.\n",
    "x_dims = 1 # The number of input dimensions: default 1.\n",
    "z_dims = d # The number of latent variable dimensions: default the same as variable size.\n",
    "epochs = 200 # Number of epochs to train.\n",
    "batch_size = 10 # Number of samples per batch. note: should be divisible by sample size, otherwise throw an error.\n",
    "n_var=5\n",
    "\n",
    "n_times=30 #no. of replicates\n",
    "time_stamp=10 #no. of timestamp\n",
    "np.random.seed(1234567) #Random seed\n",
    "seed_list=np.random.randint(1, 1000000, size=n_times)\n",
    "average_coef_list=np.zeros((n_times,time_stamp,n_var,n_var))\n",
    "B_list=np.zeros((n_times,d, d))\n",
    "FDR_total=[]\n",
    "TPR_total=[]\n",
    "SHD_total=[]\n",
    "time_list=[]\n",
    "for replicate in range(n_times):\n",
    "  seed=seed_list[replicate]\n",
    "  print(seed)\n",
    "  X_all=simulate_lsem_dynamic(W_all,Z_graph,30,10, 'Binary',noise_scale=0.1).reshape(330,5,1) #create data\n",
    "  average_list=np.zeros((time_stamp,d, d))\n",
    "  FDR_list_piece=[]\n",
    "  TPR_list_piece=[]\n",
    "  SHD_list_piece=[]\n",
    "  base_DAG=np.zeros((5, 5))\n",
    "  ####estimate at each time_stamp####\n",
    "  timestart=time.time()\n",
    "  for j in range(time_stamp):\n",
    "  # ----------- Configurations:\n",
    "      k_max_iter = int(1e2) # The max iteration number for searching parameters.\n",
    "      original_lr = 3e-3  # Initial learning rate.\n",
    "      encoder_hidden = d^2 # Number of hidden units, adaptive to dimension of nodes (d^2).\n",
    "      decoder_hidden = d^2 # Number of hidden units, adaptive to dimension of nodes (d^2).\n",
    "      temp = 0.5 # Temperature for Gumbel softmax.\n",
    "      factor = True # Factor graph model.\n",
    "      encoder_dropout = 0.0 # Dropout rate (1 - keep probability).\n",
    "      decoder_dropout = 0.0 # Dropout rate (1 - keep probability).\n",
    "      tau_A = 0. # Coefficient for L-1 norm of matrix B.\n",
    "      lambda1 = 0. # Coefficient for DAG constraint h1(B).\n",
    "      c_B = 1 # Coefficient for absolute value h1(B).\n",
    "      h1_tol = 1e-8 # The tolerance of error of h1(B) to zero.\n",
    "      lr_decay = 200 # After how many epochs to decay LR by a factor of gamma. \n",
    "      gamma = 1.0 # LR decay factor. \n",
    "      ######################\n",
    "\n",
    "\n",
    "      X=X_all[(j*30):(j*30+30),:]\n",
    "\n",
    "\n",
    "      np.random.seed(seed)\n",
    "      random.seed(seed)\n",
    "      torch.manual_seed(seed)\n",
    "      feat_train = torch.FloatTensor(X)\n",
    "      feat_valid = torch.FloatTensor(X)\n",
    "      feat_test = torch.FloatTensor(X)\n",
    "\n",
    "      # Reconstruct itself\n",
    "      train_data = TensorDataset(feat_train, feat_train)\n",
    "      valid_data = TensorDataset(feat_valid, feat_train)\n",
    "      test_data = TensorDataset(feat_test, feat_train)\n",
    "\n",
    "      train_loader = DataLoader(train_data, batch_size = batch_size)\n",
    "      valid_loader = DataLoader(valid_data, batch_size = batch_size)\n",
    "      test_loader = DataLoader(test_data, batch_size = batch_size)\n",
    "\n",
    "      # ----------- Load modules:\n",
    "      off_diag = np.ones([d, d]) - np.eye(d) # Generate off-diagonal interaction graph\n",
    "      rel_rec = np.array(encode_onehot(np.where(off_diag)[1]), dtype = np.float64)\n",
    "      rel_send = np.array(encode_onehot(np.where(off_diag)[0]), dtype = np.float64)\n",
    "      rel_rec = torch.DoubleTensor(rel_rec)\n",
    "      rel_send = torch.DoubleTensor(rel_send)\n",
    "      adj_A = np.zeros((d, d)) # Add adjacency matrix\n",
    "\n",
    "      encoder = MLPEncoder(d * x_dims, x_dims, encoder_hidden,\n",
    "                              int(z_dims), adj_A,\n",
    "                              batch_size = batch_size,\n",
    "                              do_prob = encoder_dropout, factor = factor).double()\n",
    "      decoder = MLPDecoder(d * x_dims,\n",
    "                              z_dims, x_dims, encoder,\n",
    "                              data_variable_size = d,\n",
    "                              batch_size = batch_size,\n",
    "                              n_hid=decoder_hidden,\n",
    "                              do_prob=decoder_dropout).double()\n",
    "\n",
    "      # ----------- Set up optimizer:\n",
    "      optimizer = optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr = original_lr)\n",
    "      scheduler = lr_scheduler.StepLR(optimizer, step_size = lr_decay,\n",
    "                                      gamma = gamma)\n",
    "\n",
    "      rel_rec = Variable(rel_rec)\n",
    "      rel_send = Variable(rel_send)\n",
    "\n",
    "      # ----------- Main:\n",
    "      best_ELBO_loss = np.inf\n",
    "      best_NLL_loss = np.inf\n",
    "      best_MSE_loss = np.inf\n",
    "      h1_B_new = torch.tensor(1.)\n",
    "      h2_B_new = 1\n",
    "      h1_B_old = np.inf\n",
    "      h2_B_old = np.inf\n",
    "      lr = original_lr\n",
    "    \n",
    "\n",
    "      try:\n",
    "          for step_k in range(k_max_iter):\n",
    "              while c_B< 1e+20:\n",
    "                  for epoch in range(epochs):\n",
    "                      old_lr = lr \n",
    "                      ELBO_loss, NLL_loss, MSE_loss, origin_B, optimizer, lr = train(epoch, lambda1, c_B, optimizer, old_lr)\n",
    "\n",
    "                      if ELBO_loss < best_ELBO_loss:\n",
    "                          best_ELBO_loss = ELBO_loss\n",
    "\n",
    "                      if NLL_loss < best_NLL_loss:\n",
    "                          best_NLL_loss = NLL_loss\n",
    "\n",
    "                      if MSE_loss < best_MSE_loss:\n",
    "                          best_MSE_loss = MSE_loss\n",
    "\n",
    "                  if ELBO_loss > 2 * best_ELBO_loss:\n",
    "                      break\n",
    "\n",
    "                  # Update parameters\n",
    "                  B_new = origin_B.data.clone()\n",
    "                  h1_B_new =  _h_A(B_new,d)\n",
    "                  if h1_B_new.item() > 0.25 * h1_B_old:\n",
    "                      c_B *= 10\n",
    "                  else:\n",
    "                      break\n",
    "\n",
    "              # Update parameters    \n",
    "              h1_B_old = h1_B_new.item()\n",
    "              lambda1 += c_B * h1_B_new.item()\n",
    "\n",
    "              if h1_B_new.item() <= h1_tol:\n",
    "                  break\n",
    "\n",
    "      except KeyboardInterrupt:\n",
    "          print('KeyboardInterrupt')\n",
    "\n",
    "      predB = np.matrix(origin_B.data.clone().numpy())\n",
    "      print('Best ELBO Loss :', best_ELBO_loss)\n",
    "      print('Best NLL Loss :', best_NLL_loss)\n",
    "      print('Best MSE Loss :', best_MSE_loss)\n",
    "      #calculate_effect(predB)\n",
    "      print(j)\n",
    "      average_list[j,:,:]=predB\n",
    "\n",
    "\n",
    "\n",
    "  average_coef_list[replicate,:,:,:]=average_list #average coef save to matrix\n",
    "  np.save(\"quadra_10_30_DAGGNN_lag\",average_coef_list)\n",
    "#   timeend=time.time()\n",
    "#   time_list.append(timeend-timestart)\n",
    "  #print(timeend-timestart)\n",
    "  #####write at every epoch\n",
    "  #df.to_csv(\"cos_rep10.csv\")\n",
    "  print(replicate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200d5e21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Copy of 100_rep_simulation_dim_5-cos_error.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
