{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "14283b70",
   "metadata": {
    "id": "14283b70",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy import interpolate\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7c5e29b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data.dataset import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import scipy.linalg as slin\n",
    "import scipy.sparse as sp\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from pandas import ExcelWriter\n",
    "from pandas import ExcelFile\n",
    "import glob\n",
    "import re\n",
    "import math\n",
    "from torch.optim.adam import Adam\n",
    "from utils import *\n",
    "from statistics import mean\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d89455d",
   "metadata": {
    "id": "1d89455d"
   },
   "source": [
    "## create basis & function demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7da3d05e",
   "metadata": {
    "id": "7da3d05e"
   },
   "outputs": [],
   "source": [
    "np.random.seed(1234567)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b115afe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def simulate_random_dag(d: int,\n",
    "                        degree: float,\n",
    "                        w_range: tuple = (1.0, 1.0)) -> nx.DiGraph:\n",
    "    \"\"\"Simulate random DAG with an expected degree by Erdos-Renyi model.\n",
    "        \n",
    "        Args:\n",
    "        d: number of nodes\n",
    "        degree: expected node degree, in + out\n",
    "        w_range: weight range +/- (low, high)\n",
    "        \n",
    "        Returns:\n",
    "        G: weighted DAG\n",
    "        \"\"\"\n",
    "    prob = float(degree) / (d - 1)\n",
    "    B = np.tril((np.random.rand(d, d) < prob).astype(float), k=-1)\n",
    "    \n",
    "    # random permutation\n",
    "    P = np.random.permutation(np.eye(d, d))  # permutes first axis only\n",
    "    B_perm = P.T.dot(B).dot(P)\n",
    "    U = np.random.uniform(low=w_range[0], high=w_range[1], size=[d, d])\n",
    "    U[np.random.rand(d, d) < 0.5] *= -1\n",
    "    W = (B_perm != 0).astype(float) * U\n",
    "    \n",
    "    # remove all in-edges (from precedent nodes) of the first node as A\n",
    "    W[:, 0] = 0\n",
    "    # remove all out-edges (from descendent nodes) of the last node as Y\n",
    "    W[d-1, :] = 0\n",
    "    # the remained nodes are the mediators M; and reset mediators if it has higher topological order than A or lower order than Y.\n",
    "    ordered_vertices = list(nx.topological_sort(nx.DiGraph(W)))\n",
    "    j = 1\n",
    "    while j < d - 1:\n",
    "        if  ordered_vertices.index(j) < ordered_vertices.index(0):\n",
    "            W[j, 1:(d - 1)] = np.zeros (d - 2)\n",
    "        if  ordered_vertices.index(j) > ordered_vertices.index(d - 1):\n",
    "            W[1:(d - 1), j] = np.zeros (d - 2)\n",
    "        j = j + 1\n",
    "    #print(\"True weighted adjacency matrix B:\\n\", W)\n",
    "    G = nx.DiGraph(W)\n",
    "    calculate_effect(W)\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9af8cc7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total effect (TE): 0.0\n",
      "The natural direct effect (DE): 0.0\n",
      "The natural indirect effect (IE): 0.0\n",
      "The natural direct effect for mediators (DM): [ 0.  0. -0.]\n",
      "The natural direct effect for mediators (IM): [0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0., -1., -0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., -0.],\n",
       "       [ 0.,  1., -0.,  0.,  1.],\n",
       "       [ 0., -0.,  0.,  0., -0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(123456)\n",
    "base_DAG=simulate_random_dag(5,4)\n",
    "base_DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a373aa83",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1234567)\n",
    "pick_element=random.sample(range(5), 2) ## pick two location to mutate\n",
    "pick_1=np.nonzero(base_DAG)[0][pick_element[0]],np.nonzero(base_DAG)[1][pick_element[0]]\n",
    "pick_2=np.nonzero(base_DAG)[0][pick_element[1]],np.nonzero(base_DAG)[1][pick_element[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e63f5277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(base_DAG.T, cmap = 'bwr', vmin = -1, vmax = 1)\n",
    "fig1 = plt.gcf()\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d1a244e",
   "metadata": {
    "id": "6d1a244e"
   },
   "outputs": [],
   "source": [
    "import math \n",
    "def cos(x):\n",
    "    return ((math.cos(x/6*math.pi))/4+1)*0.8\n",
    "def quadratic(x):\n",
    "    return(-5+(10-x)**2)/200+0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bd964c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: [0.   0.   0.   2.25 4.5  6.75 9.   9.   9.  ]\n",
      "c: [1. 1. 1. 1. 1. 1. 0. 0. 0.]\n",
      "k: 2\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "degree =2\n",
    "time_point=10\n",
    "x = np.array(range(0, time_point))\n",
    "#y = np.array([cos(i)+np.random.normal(0, 0.1, 1) for i in x])\n",
    "y = np.array([1 for i in x])\n",
    "#y = np.array([1 for i in x])\n",
    "z= [1 for i in np.array(range(0, time_point*10))]\n",
    "m = 3\n",
    "step = (x[-1] - x[0]) / (m + 1)\n",
    "knots = np.linspace(step, m * step, m)\n",
    "\n",
    "t, c, k = interpolate.splrep(x, y, k=degree, s=0, t=knots, per=0)\n",
    "\n",
    "print('''\\\n",
    "t: {}\n",
    "c: {}\n",
    "k: {}\n",
    "'''.format(t, c, k))\n",
    "N = 100\n",
    "xmin, xmax = x.min(), x.max()\n",
    "xx = np.linspace(xmin, xmax, N)\n",
    "spline = interpolate.BSpline(t, c, k, extrapolate=False)\n",
    "\n",
    "plt.plot(x, y, label='data points')\n",
    "plt.plot(xx, spline(xx), label='BSpline')\n",
    "plt.plot([i/10 for i in np.array(range(0, time_point*10))], z, label='coef without error')\n",
    "plt.grid()\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1f498d7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 351
    },
    "id": "b1f498d7",
    "outputId": "337ffdf2-8eee-4e75-97b3-51ae278a7cb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: [0.   0.   0.   2.25 4.5  6.75 9.   9.   9.  ]\n",
      "c: [0.99990351 0.99634813 0.75384184 0.56636058 0.66701045 0.80050726\n",
      " 0.         0.         0.        ]\n",
      "k: 2\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "degree =2\n",
    "time_point=10\n",
    "x = np.array(range(0, time_point))\n",
    "#y = np.array([cos(i)+np.random.normal(0, 0.1, 1) for i in x])\n",
    "y = np.array([cos(i) for i in x])\n",
    "#y = np.array([1 for i in x])\n",
    "z= [cos(i/10) for i in np.array(range(0, time_point*10))]\n",
    "m = 3\n",
    "step = (x[-1] - x[0]) / (m + 1)\n",
    "knots = np.linspace(step, m * step, m)\n",
    "\n",
    "t, c, k = interpolate.splrep(x, y, k=degree, s=0, t=knots, per=0)\n",
    "\n",
    "print('''\\\n",
    "t: {}\n",
    "c: {}\n",
    "k: {}\n",
    "'''.format(t, c, k))\n",
    "N = 100\n",
    "xmin, xmax = x.min(), x.max()\n",
    "xx = np.linspace(xmin, xmax, N)\n",
    "spline = interpolate.BSpline(t, c, k, extrapolate=False)\n",
    "\n",
    "plt.plot(x, y, label='data points')\n",
    "plt.plot(xx, spline(xx), label='BSpline')\n",
    "plt.plot([i/10 for i in np.array(range(0, time_point*10))], z, label='coef without error')\n",
    "plt.grid()\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c0b2a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: [0.   0.   0.   2.25 4.5  6.75 9.   9.   9.  ]\n",
      "c: [0.975    0.8625   0.688125 0.564375 0.49125  0.48     0.       0.\n",
      " 0.      ]\n",
      "k: 2\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "degree =2\n",
    "time_point=10\n",
    "x = np.array(range(0, time_point))\n",
    "#y = np.array([cos(i)+np.random.normal(0, 0.1, 1) for i in x])\n",
    "y = np.array([quadratic(i) for i in x])\n",
    "z= [quadratic(i/10) for i in np.array(range(0, time_point*10))]\n",
    "m = 3\n",
    "step = (x[-1] - x[0]) / (m + 1)\n",
    "knots = np.linspace(step, m * step, m)\n",
    "\n",
    "t, c, k = interpolate.splrep(x, y, k=degree, s=0, t=knots, per=0)\n",
    "\n",
    "print('''\\\n",
    "t: {}\n",
    "c: {}\n",
    "k: {}\n",
    "'''.format(t, c, k))\n",
    "N = 100\n",
    "xmin, xmax = x.min(), x.max()\n",
    "xx = np.linspace(xmin, xmax, N)\n",
    "spline = interpolate.BSpline(t, c, k, extrapolate=False)\n",
    "\n",
    "plt.plot(x, y, label='data points')\n",
    "plt.plot(xx, spline(xx), label='BSpline')\n",
    "plt.plot([i/10 for i in np.array(range(0, time_point*10))], z, label='coef without error')\n",
    "plt.grid()\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ca93bbd",
   "metadata": {
    "id": "7ca93bbd"
   },
   "outputs": [],
   "source": [
    "from scipy.interpolate import BSpline\n",
    "k = 3\n",
    "t = t\n",
    "c1 = [1,0,0,0,0,0]\n",
    "c2 = [0,1,0,0,0,0]\n",
    "c3 = [0,0,1,0,0,0]\n",
    "c4 = [0,0,0,1,0,0]\n",
    "c5 = [0,0,0,0,1,0]\n",
    "c6 = [0,0,0,0,0,1]\n",
    "spl1 = BSpline(t, c1, k)\n",
    "spl2 = BSpline(t, c2, k)\n",
    "spl3 = BSpline(t, c3, k)\n",
    "spl4 = BSpline(t, c4, k)\n",
    "spl5 = BSpline(t, c5, k)\n",
    "spl6 = BSpline(t, c6, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e0f471e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "8e0f471e",
    "outputId": "502f249b-3175-455f-f521-052e4f099891"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "xx = np.linspace(0, time_point, 50)\n",
    "ax.plot(xx, spl1(xx), lw=3, label='Bspline1')\n",
    "ax.plot(xx, spl2(xx), lw=4, alpha=0.7, label='Bspline2')\n",
    "ax.plot(xx, spl3(xx), lw=4, alpha=0.7, label='Bspline3')\n",
    "ax.plot(xx, spl4(xx), lw=4, alpha=0.7, label='Bspline4')\n",
    "ax.plot(xx, spl5(xx), lw=4, alpha=0.7, label='Bspline5')\n",
    "ax.plot(xx, spl6(xx), lw=4, alpha=0.7, label='Bspline6')\n",
    "ax.grid(True)\n",
    "ax.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fcf3e1",
   "metadata": {
    "id": "e1fcf3e1"
   },
   "source": [
    "## create data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "V6gVN_VTxnG4",
   "metadata": {
    "id": "V6gVN_VTxnG4"
   },
   "outputs": [],
   "source": [
    "def data_create(seed,time_stamp,set_graph):\n",
    "  np.random.seed(seed)\n",
    "  x = np.array(range(0, time_stamp))\n",
    "  #y = np.array([cos(i)+np.random.normal(0, 0.1, 1) for i in x]) #generate coefficient\n",
    "  y=np.array([cos(i) for i in x])\n",
    "  z=np.array([quadratic(i) for i in x])##edited to have multiple\n",
    "  base_DAG=set_graph \n",
    "  base_DAG[pick_1]=y[0]##edited to be coeffcient with error\n",
    "  base_DAG[pick_2]=z[0]###multiple\n",
    "  base_graph=nx.from_numpy_matrix(base_DAG,create_using=nx.DiGraph)\n",
    "  X_all = simulate_lsem(base_graph,30, 'Binary', 1,noise_scale=0.1)\n",
    "  for i in range(1,time_stamp):\n",
    "      base_DAG[pick_1]=y[i]##edited to be coeffcient with error\n",
    "      base_DAG[pick_2]=z[i]###multiple\n",
    "      base_graph=nx.from_numpy_matrix(base_DAG,create_using=nx.DiGraph)\n",
    "      X = simulate_lsem(base_graph,30, 'Binary', 1,noise_scale=0.1)\n",
    "      X_all=np.append(X_all,X,axis=0)\n",
    "      print(base_DAG)\n",
    "  return X_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c16e796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.         -1.         -0.          0.88        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.97320508]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.795  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.9  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.72  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "[[ 0.    -1.    -0.     0.655  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.6         0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.555  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.6  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.52        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.495  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.48  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n"
     ]
    }
   ],
   "source": [
    "n = 30 # The number of samples of data.\n",
    "d = 5 # The number of variables in data.\n",
    "time_stamp=10 #no. of timestamp\n",
    "np.random.seed(1234567) #Random seed\n",
    "n_times=30\n",
    "seed_list=np.random.randint(1, 1000000, size=n_times)\n",
    "seed=seed_list[0]\n",
    "X_all=data_create(seed,time_stamp,base_DAG) #create data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "faba8df9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 5, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all.shape #(30*10)*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1766d8b",
   "metadata": {
    "id": "f1766d8b"
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import time\n",
    "import argparse\n",
    "import pickle\n",
    "import os\n",
    "import random\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import math\n",
    "from utils import *\n",
    "\n",
    "from multiprocessing import Pool\n",
    "import multiprocessing\n",
    "n_cores = multiprocessing.cpu_count()\n",
    "from numpy.random import randn\n",
    "from random import seed as rseed\n",
    "from numpy.random import seed as npseed\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b6be67",
   "metadata": {
    "id": "42b6be67"
   },
   "source": [
    "# new method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "42046e3c",
   "metadata": {
    "id": "42046e3c"
   },
   "outputs": [],
   "source": [
    "# ----------- Configurations:\n",
    "time_stamp=10\n",
    "n_timestamp=time_stamp\n",
    "sample__time=30##sample per timepoint\n",
    "n = time_stamp*sample__time # The number of samples of data.\n",
    "n_var = 5 # The number of variables in data.\n",
    "x_dims = 1 # The number of input dimensions: default 1.\n",
    "z_dims = n_var # The number of latent variable dimensions: default the same as variable size.\n",
    "epochs = 200 # Number of epochs to train.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7871866b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7871866b",
    "outputId": "95d27f29-9ad4-41bb-a565-112fc3b458d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b4a5750",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2b4a5750",
    "outputId": "c445bb2c-a8f6-47b5-b509-6845875ddd96"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample__time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "57724831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 5, 1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "93a046a5",
   "metadata": {
    "id": "93a046a5"
   },
   "outputs": [],
   "source": [
    "def create_D(X,spline_list):\n",
    "    D_all=np.zeros((sample__time*time_stamp, n_var*len(spline_list),1))\n",
    "    for j in range(len(spline_list)):\n",
    "        D_column=np.zeros((sample__time*time_stamp, n_var,1))#for each spline\n",
    "        for i in range(0,n_timestamp):\n",
    "            D_column[(sample__time*i):(sample__time*(i+1)),:,:]=X[(sample__time*i):(sample__time*(i+1)),:]*spline_list[j](i)#X_i *f(i), stack horizontally\n",
    "        ##horizontally append\n",
    "        D_all[:,n_var*j:n_var*(j+1),:]=D_column\n",
    "        #print((n_features*j,n_features*(j+1)))\n",
    "    return(D_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5880a65f",
   "metadata": {
    "id": "5880a65f"
   },
   "outputs": [],
   "source": [
    "#spline_list=[spl_const]\n",
    "spline_list=[spl1,spl2,spl3,spl4,spl5,spl6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9bdb6397",
   "metadata": {
    "id": "9bdb6397"
   },
   "outputs": [],
   "source": [
    "def spl_consraint(spline_list,t,p):\n",
    "    k=len(spline_list)\n",
    "    output=torch.zeros(((p*k), p))\n",
    "    identity=torch.zeros((p, p*k))\n",
    "    for i in range(k):\n",
    "        output[(i*p):(i*p+p),:]=torch.ones((p,p))*spline_list[i](t).item() #gamma times basis\n",
    "        identity[:,(i*p):(i*p+p)]=torch.eye(p) #stacked identity matrix\n",
    "    #final=torch.matmul(identity,output)\n",
    "    return output, identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "985dc159",
   "metadata": {
    "id": "985dc159"
   },
   "outputs": [],
   "source": [
    "# ----------- Configurations:\n",
    "n = 30*time_stamp # The number of samples of data.\n",
    "d = 36 # The number of variables in data after spline.  (p+1*k)\n",
    "x_dims = 1 # The number of input dimensions: default 1.\n",
    "z_dims = d # The number of latent variable dimensions: default the same as variable size.\n",
    "epochs = 200 # Number of epochs to train.\n",
    "batch_size = 10 # Number of samples per batch. note: should be divisible by sample size, otherwise throw an error.\n",
    "k_max_iter = int(1e2) # The max iteration number for searching parameters.\n",
    "original_lr = 3e-3  # Initial learning rate.\n",
    "encoder_hidden = d^2 # Number of hidden units, adaptive to dimension of nodes (d^2).\n",
    "decoder_hidden = d^2 # Number of hidden units, adaptive to dimension of nodes (d^2).\n",
    "temp = 0.5 # Temperature for Gumbel softmax.\n",
    "factor = True # Factor graph model.\n",
    "encoder_dropout = 0.0 # Dropout rate (1 - keep probability).\n",
    "decoder_dropout = 0.0 # Dropout rate (1 - keep probability).\n",
    "tau_B = 0. # Coefficient for L-1 norm of matrix B.\n",
    "lambda1 = 0. # Coefficient for DAG constraint h1(B).\n",
    "lambda2 = 0. # Coefficient for identification constraint h2(B).\n",
    "c_B = 1 # Coefficient for absolute value h1(B).\n",
    "d_B = 1 # Coefficient for absolute value h2(B).\n",
    "e_B = 1 # Coefficient for absolute value h3(B)\n",
    "h1_tol = 1e-8 # The tolerance of error of h1(B) to zero.\n",
    "h2_tol = 1e-8 # The tolerance of error of h2(B) to zero.\n",
    "h3_tol = 1e-8 # The tolerance of error of h2(B) to zero.\n",
    "lr_decay = 200 # After how many epochs to decay LR by a factor of gamma. \n",
    "gamma = 1.0 # LR decay factor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4c588ed1",
   "metadata": {
    "id": "4c588ed1"
   },
   "outputs": [],
   "source": [
    "def fun_h2_B_new(B):\n",
    "    '''compute constraint h2(B) value'''\n",
    "    d = B.shape[0]\n",
    "    gamma=B[p:,:p]\n",
    "    h3_B = sum(sum(abs(B[:p, :])))+sum(abs(gamma[:, 0]))+sum(sum(abs(B[p:, p:]))) # uppper 0 and 0 column and every p-1,2p-1 row\n",
    "    for i in range(k):\n",
    "        h3_B=h3_B+sum(abs(gamma[((i+1)*p-1), 1:]))\n",
    "    return h3_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "705f6778",
   "metadata": {
    "id": "705f6778"
   },
   "outputs": [],
   "source": [
    "def fun_h1_B(B):\n",
    "    '''compute constraint h1(B) value'''\n",
    "    d = B.shape[0]\n",
    "    expm_B = matrix_poly(B * B, d)\n",
    "    h1_B = torch.trace(expm_B) - d\n",
    "    return h1_B.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "feedc251",
   "metadata": {
    "id": "feedc251"
   },
   "outputs": [],
   "source": [
    "def train_new(epoch, lambda1, c_B, lambda2, d_B, optimizer, old_lr,p,k):\n",
    "        \n",
    "        nll_train = []\n",
    "        kl_train = []\n",
    "        mse_train = []\n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "        scheduler.step()\n",
    "\n",
    "        # Update optimizer\n",
    "        optimizer, lr = update_optimizer(optimizer, old_lr, c_B, d_B)\n",
    "\n",
    "        for batch_idx, (data, relations) in enumerate(train_loader):\n",
    "\n",
    "            data, relations = Variable(data).double(), Variable(relations).double()\n",
    "            relations = relations.unsqueeze(2) # Reshape data\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            enc_x, logits, origin_B, adj_A_tilt_encoder, z_gap, z_positive, myA, Wa = encoder(data, rel_rec, rel_send) \n",
    "            edges = logits # Logits is of size: [num_sims, z_dims]\n",
    "\n",
    "            dec_x, output, adj_A_tilt_decoder = decoder(data, edges, d * x_dims, rel_rec, rel_send, origin_B, adj_A_tilt_encoder, Wa)\n",
    "\n",
    "            if torch.sum(output != output):\n",
    "                print('nan error\\n')\n",
    "\n",
    "            target = data\n",
    "            preds = output\n",
    "            variance = 0.\n",
    "            \n",
    "            # Compute constraint functions h1(B) and h2(B)\n",
    "            #h1_B = fun_h1_B(origin_B[p:,p:]) #acyclity on G\n",
    "            h1_B =0\n",
    "            for i in range(n_timestamp):\n",
    "                #aa=torch.matmul(spl_consraint(spline_list,i,p).type(torch.FloatTensor),origin_B[p:,:p].type(torch.FloatTensor))#acyclity on Gamma\n",
    "                #print(fun_h1_B(aa))\n",
    "                output, identity=spl_consraint(spline_list,i,p)\n",
    "                h1_B=h1_B+fun_h1_B(torch.matmul(identity.type(torch.FloatTensor),(output.type(torch.FloatTensor)*origin_B[p:,:p].type(torch.FloatTensor))))#acyclity on Gamma\n",
    "            h2_B = fun_h2_B_new(origin_B) ##handle the zero on gamma and top\n",
    "            # Reconstruction accuracy loss:\n",
    "            loss_nll = nll_gaussian(preds, target, variance)\n",
    "            # KL loss:\n",
    "            loss_kl = kl_gaussian(logits)\n",
    "            # ELBO loss:\n",
    "            loss = loss_kl + loss_nll\n",
    "            # Loss function:\n",
    "            loss += lambda1 * h1_B + 0.5 * c_B * h1_B * h1_B + lambda2 * h2_B + 0.5 * d_B * h2_B * h2_B + 100. * torch.trace(origin_B * origin_B)\n",
    "\n",
    "            loss.backward()\n",
    "            loss = optimizer.step()\n",
    "\n",
    "            myA.data = stau(myA.data, tau_B * lr)\n",
    "\n",
    "            if torch.sum(origin_B != origin_B):\n",
    "                print('nan error\\n')\n",
    "\n",
    "            mse_train.append(F.mse_loss(preds, target).item())\n",
    "            nll_train.append(loss_nll.item())\n",
    "            kl_train.append(loss_kl.item())\n",
    "\n",
    "        return np.mean(np.mean(kl_train) + np.mean(nll_train)), np.mean(nll_train), np.mean(mse_train), origin_B, optimizer, lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b76390df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.  , -1.  , -0.  ,  0.48,  0.  ],\n",
       "       [ 0.  ,  0.  ,  0.  ,  0.  , -0.  ],\n",
       "       [ 0.  ,  1.  , -0.  ,  0.  ,  0.8 ],\n",
       "       [ 0.  , -0.  ,  0.  ,  0.  , -0.  ],\n",
       "       [ 0.  ,  0.  ,  0.  ,  0.  ,  0.  ]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "54a4ea69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import BSpline\n",
    "def spline_create(m):\n",
    "    degree =2\n",
    "    x = np.array(range(0, 11))\n",
    "    y = np.array([cos(i) for i in x])\n",
    "    z= [cos(i/10) for i in np.array(range(0, 110))]\n",
    "    step = (x[-1] - x[0]) / (m + 1)\n",
    "    knots = np.linspace(step, m * step, m)\n",
    "\n",
    "    t, c, k = interpolate.splrep(x, y, k=degree, s=0, t=knots, per=0)\n",
    "\n",
    "    print('''\\\n",
    "    t: {}\n",
    "    c: {}\n",
    "    k: {}\n",
    "    '''.format(t, c, k))\n",
    "    N = 100\n",
    "    xmin, xmax = x.min(), x.max()\n",
    "    xx = np.linspace(xmin, xmax, N)\n",
    "    spline = interpolate.BSpline(t, c, k, extrapolate=False)\n",
    "    ##get the spline\n",
    "    k = 2\n",
    "    t = t\n",
    "    c1 = [1,0,0,0,0,0,0,0]\n",
    "    c2 = [0,1,0,0,0,0,0,0]\n",
    "    c3 = [0,0,1,0,0,0,0,0]\n",
    "    c4 = [0,0,0,1,0,0,0,0]\n",
    "    c5 = [0,0,0,0,1,0,0,0]\n",
    "    c6 = [0,0,0,0,0,1,0,0]\n",
    "    c7 = [0,0,0,0,0,0,1,0]\n",
    "    c8 = [0,0,0,0,0,0,0,1]\n",
    "    spl1 = BSpline(t, c1, k)\n",
    "    spl2 = BSpline(t, c2, k)\n",
    "    spl3 = BSpline(t, c3, k)\n",
    "    spl4 = BSpline(t, c4, k)\n",
    "    spl5 = BSpline(t, c5, k)\n",
    "    spl6 = BSpline(t, c6, k)\n",
    "    spl7 = BSpline(t, c7, k)\n",
    "    spl8 = BSpline(t, c8, k)\n",
    "    \n",
    "    spline_list=[spl1,spl2,spl3,spl4,spl5,spl6,spl7,spl8]\n",
    "    spline_list=spline_list[:(m+k+1)]\n",
    "    return(spline_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e70f06ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.         -1.         -0.          0.88        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.97320508]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.795  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.9  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.72  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "[[ 0.    -1.    -0.     0.655  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.6         0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.555  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.6  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.52        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.495  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.48  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "    t: [ 0.  0.  0.  5. 10. 10. 10.]\n",
      "    c: [1.02820318 0.82005058 0.4918023  0.92528792 0.         0.\n",
      " 0.        ]\n",
      "    k: 2\n",
      "    \n",
      "(300, 25, 1)\n",
      "knots= 1 folds= 0\n",
      "(240, 25, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2463.2737090587616\n",
      "mse_valid: 1.239459764009594e-07 nll_valid: 1.5493247050119917e-06 kl_valid: 0.00034973085630861167\n",
      "knots= 1 folds= 1\n",
      "(240, 25, 1)\n",
      "2193.166297197342\n",
      "mse_valid: 5.376657205848891e-07 nll_valid: 6.720821507311107e-06 kl_valid: 0.0002884108131259265\n",
      "knots= 1 folds= 2\n",
      "(240, 25, 1)\n",
      "1966.0918672084808\n",
      "mse_valid: 1.9495295280957003e-05 nll_valid: 0.0002436911910119625 kl_valid: 0.00028828507347216563\n",
      "knots= 1 folds= 3\n",
      "(240, 25, 1)\n",
      "1970.206442117691\n",
      "mse_valid: 4.0896935456579003e-07 nll_valid: 5.112116932072378e-06 kl_valid: 0.0002874160694829272\n",
      "knots= 1 folds= 4\n",
      "(240, 25, 1)\n",
      "2179.562173128128\n",
      "mse_valid: 1.0233997519131087e-05 nll_valid: 0.00012792496898913848 kl_valid: 0.0002736959107881131\n",
      "    t: [ 0.          0.          0.          3.33333333  6.66666667 10.\n",
      " 10.         10.        ]\n",
      "    c: [1.0014131  0.97520621 0.55363068 0.68795566 0.90571202 0.\n",
      " 0.         0.        ]\n",
      "    k: 2\n",
      "    \n",
      "(300, 30, 1)\n",
      "knots= 2 folds= 0\n",
      "(240, 30, 1)\n",
      "2151.9335622787476\n",
      "mse_valid: 8.04069476170287e-06 nll_valid: 0.00012061042142554308 kl_valid: 0.00038112272152662443\n",
      "knots= 2 folds= 1\n",
      "(240, 30, 1)\n",
      "2372.039099931717\n",
      "mse_valid: 2.4260009057103823e-05 nll_valid: 0.0003639001358565569 kl_valid: 0.0003576223566073772\n",
      "knots= 2 folds= 2\n",
      "(240, 30, 1)\n",
      "2153.1541924476624\n",
      "mse_valid: 1.0475202102275661e-08 nll_valid: 1.5712803153413486e-07 kl_valid: 0.00036895111342204743\n",
      "knots= 2 folds= 3\n",
      "(240, 30, 1)\n",
      "2134.379707336426\n",
      "mse_valid: 2.516382883435072e-08 nll_valid: 3.77457432515261e-07 kl_valid: 0.0003431365291957314\n",
      "knots= 2 folds= 4\n",
      "(240, 30, 1)\n",
      "2197.2843520641327\n",
      "mse_valid: 3.09916279526929e-05 nll_valid: 0.00046487441929039336 kl_valid: 0.0003711217462181474\n",
      "    t: [ 0.   0.   0.   2.5  5.   7.5 10.  10.  10. ]\n",
      "    c: [0.99991746 0.99417142 0.70604452 0.55383763 0.76591268 0.90076467\n",
      " 0.         0.         0.        ]\n",
      "    k: 2\n",
      "    \n",
      "(300, 35, 1)\n",
      "knots= 3 folds= 0\n",
      "(240, 35, 1)\n",
      "2706.773115158081\n",
      "mse_valid: 2.1224072539923697e-08 nll_valid: 3.7142126944866443e-07 kl_valid: 0.0003311156325229467\n",
      "knots= 3 folds= 1\n",
      "(240, 35, 1)\n",
      "2693.299176454544\n",
      "mse_valid: 5.587530302302489e-08 nll_valid: 9.778178029029356e-07 kl_valid: 0.00029870410939717524\n",
      "knots= 3 folds= 2\n",
      "(240, 35, 1)\n",
      "2385.976422548294\n",
      "mse_valid: 1.9059950189986717e-06 nll_valid: 3.335491283247678e-05 kl_valid: 0.00034330070768752034\n",
      "knots= 3 folds= 3\n",
      "(240, 35, 1)\n",
      "2864.0647575855255\n",
      "mse_valid: 3.856056498016227e-07 nll_valid: 6.7480988715284025e-06 kl_valid: 0.00032840629911428266\n",
      "knots= 3 folds= 4\n",
      "(240, 35, 1)\n",
      "2428.569781064987\n",
      "mse_valid: 2.9164358836034593e-06 nll_valid: 5.1037627963060565e-05 kl_valid: 0.0003227693794896967\n",
      "    t: [ 0.  0.  0.  2.  4.  6.  8. 10. 10. 10.]\n",
      "    c: [0.99985556 0.99802153 0.80044379 0.60076103 0.60133354 0.79945682\n",
      " 0.90004066 0.         0.         0.        ]\n",
      "    k: 2\n",
      "    \n",
      "(300, 40, 1)\n",
      "knots= 4 folds= 0\n",
      "(240, 40, 1)\n",
      "2718.632551431656\n",
      "mse_valid: 1.921157612690917e-08 nll_valid: 3.842315225381835e-07 kl_valid: 0.0003826281506332542\n",
      "knots= 4 folds= 1\n",
      "(240, 40, 1)\n",
      "2720.183582305908\n",
      "mse_valid: 1.4866438395727312e-07 nll_valid: 2.9732876791454617e-06 kl_valid: 0.00044409254848265306\n",
      "knots= 4 folds= 2\n",
      "(240, 40, 1)\n",
      "2687.083535671234\n",
      "mse_valid: 1.4073450571603705e-07 nll_valid: 2.814690114320739e-06 kl_valid: 0.0005097297177382616\n",
      "knots= 4 folds= 3\n",
      "(240, 40, 1)\n",
      "2583.206974506378\n",
      "mse_valid: 4.23221770565936e-08 nll_valid: 8.464435411318699e-07 kl_valid: 0.00034150025188610107\n",
      "knots= 4 folds= 4\n",
      "(240, 40, 1)\n",
      "2573.130956172943\n",
      "mse_valid: 5.089350053247203e-06 nll_valid: 0.00010178700106494443 kl_valid: 0.00041993898333752937\n",
      "    t: [ 0.          0.          0.          1.66666667  3.33333333  5.\n",
      "  6.66666667  8.33333333 10.         10.         10.        ]\n",
      "    c: [0.99991485 0.99923976 0.85695917 0.67384908 0.58042106 0.64480061\n",
      " 0.81868019 0.89993868 0.         0.         0.        ]\n",
      "    k: 2\n",
      "    \n",
      "(300, 45, 1)\n",
      "knots= 5 folds= 0\n",
      "(240, 45, 1)\n",
      "2834.3366866111755\n",
      "mse_valid: 1.6871420195948703e-07 nll_valid: 3.796069544088468e-06 kl_valid: 0.00030588552621001815\n",
      "knots= 5 folds= 1\n",
      "(240, 45, 1)\n",
      "2829.027415037155\n",
      "mse_valid: 4.159028084829281e-06 nll_valid: 9.35781319086587e-05 kl_valid: 0.00031035759080745145\n",
      "knots= 5 folds= 2\n",
      "(240, 45, 1)\n",
      "3297.9018445014954\n",
      "mse_valid: 7.742767434218798e-08 nll_valid: 1.7421226726992298e-06 kl_valid: 0.00039930831927450025\n",
      "knots= 5 folds= 3\n",
      "(240, 45, 1)\n",
      "2802.104172229767\n",
      "mse_valid: 1.8413235857069798e-07 nll_valid: 4.142978067840703e-06 kl_valid: 0.0003192333188074062\n",
      "knots= 5 folds= 4\n",
      "(240, 45, 1)\n",
      "3028.79434800148\n",
      "mse_valid: 3.4553579150085456e-06 nll_valid: 7.774555308769231e-05 kl_valid: 0.00032694043955948284\n"
     ]
    }
   ],
   "source": [
    "n_var=5\n",
    "n_times=30 #no. of replicates\n",
    "time_stamp=10 #no. of timestamp\n",
    "np.random.seed(1234567) #Random seed\n",
    "seed_list=np.random.randint(1, 1000000, size=n_times)\n",
    "\n",
    "ELBO_total_new=[]\n",
    "NLL_total_new=[]\n",
    "MSE_total_new=[]\n",
    "time_list_new=[]\n",
    "\n",
    "ELBO_valid_new=[]\n",
    "NLL_valid_new=[]\n",
    "MSE_valid_new=[]\n",
    "\n",
    "seed=seed_list[0]\n",
    "X_all=data_create(seed,time_stamp,base_DAG) #create data\n",
    "for knots in range(1,6): ##for number of basis\n",
    "    spline_list=spline_create(knots)\n",
    "    D=create_D(X_all,spline_list)\n",
    "    data_all=np.append(X_all,D, axis=1)\n",
    "    print(np.shape(data_all))\n",
    "    lambda_list=np.zeros((5,(n_var*(knots+2+1)),n_var))\n",
    "    for fold in range(5): #for folds selected\n",
    "        remove_fold=list(range(fold,300+fold,5))\n",
    "        data_fold=np.delete(data_all, remove_fold, axis=0) \n",
    "        print(\"knots=\",knots,\"folds=\",fold)\n",
    "        print(np.shape(data_fold))\n",
    "\n",
    "          ####estimate at each time_stamp####\n",
    "        timestart_new=time.time()\n",
    " # ----------- Configurations:\n",
    "        p=5\n",
    "        k=knots+2+1 #no.of basis\n",
    "        n = 24*time_stamp # The number of samples of data.\n",
    "        d = p+p*k # The number of variables in data after basis.\n",
    "        x_dims = 1 # The number of input dimensions: default 1.\n",
    "        z_dims = d # The number of latent variable dimensions: default the same as variable size.\n",
    "        epochs = 200 # Number of epochs to train.\n",
    "        batch_size = 10 # Number of samples per batch. note: should be divisible by sample size, otherwise throw an error.\n",
    "        k_max_iter = int(1e2) # The max iteration number for searching parameters.\n",
    "        original_lr = 3e-3  # Initial learning rate.\n",
    "        encoder_hidden = d^2 # Number of hidden units, adaptive to dimension of nodes (d^2).\n",
    "        decoder_hidden = d^2 # Number of hidden units, adaptive to dimension of nodes (d^2).\n",
    "        temp = 0.5 # Temperature for Gumbel softmax.\n",
    "        factor = True # Factor graph model.\n",
    "        encoder_dropout = 0.0 # Dropout rate (1 - keep probability).\n",
    "        decoder_dropout = 0.0 # Dropout rate (1 - keep probability).\n",
    "        tau_B = 0. # Coefficient for L-1 norm of matrix B.\n",
    "        lambda1 = 0. # Coefficient for DAG constraint h1(B).\n",
    "        lambda2 = 0. # Coefficient for identification constraint h2(B).\n",
    "        c_B = 1 # Coefficient for absolute value h1(B).\n",
    "        d_B = 1 # Coefficient for absolute value h2(B).\n",
    "        e_B = 1 # Coefficient for absolute value h3(B)\n",
    "        h1_tol = 1e-8 # The tolerance of error of h1(B) to zero.\n",
    "        h2_tol = 1e-8 # The tolerance of error of h2(B) to zero.\n",
    "        h3_tol = 1e-8 # The tolerance of error of h2(B) to zero.\n",
    "        lr_decay = 200 # After how many epochs to decay LR by a factor of gamma. \n",
    "        gamma = 1.0 # LR decay factor.  \n",
    "        ######################\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        feat_train = torch.FloatTensor(data_fold)\n",
    "        feat_valid = torch.FloatTensor(data_all[remove_fold])\n",
    "        feat_test = torch.FloatTensor(data_fold)\n",
    "\n",
    "        # Reconstruct itself\n",
    "        train_data = TensorDataset(feat_train, feat_train)\n",
    "        valid_data = TensorDataset(feat_valid, feat_valid)\n",
    "        test_data = TensorDataset(feat_test, feat_train)\n",
    "\n",
    "        train_loader = DataLoader(train_data, batch_size = batch_size)\n",
    "        valid_loader = DataLoader(valid_data, batch_size = batch_size)\n",
    "        test_loader = DataLoader(test_data, batch_size = batch_size)\n",
    "\n",
    "        # ----------- Load modules:\n",
    "        d1=p+p*k\n",
    "        off_diag = np.ones([d1, d1]) - np.eye(d1) # Generate off-diagonal interaction graph\n",
    "        rel_rec = np.array(encode_onehot(np.where(off_diag)[1]), dtype = np.float64)\n",
    "        rel_send = np.array(encode_onehot(np.where(off_diag)[0]), dtype = np.float64)\n",
    "        rel_rec = torch.DoubleTensor(rel_rec)\n",
    "        rel_send = torch.DoubleTensor(rel_send)\n",
    "        adj_A = np.zeros((d1, d1)) # Add adjacency matrix\n",
    "\n",
    "        encoder = MLPEncoder(d1 * x_dims, x_dims, encoder_hidden,\n",
    "                              int(z_dims), adj_A,\n",
    "                              batch_size = batch_size,\n",
    "                              do_prob = encoder_dropout, factor = factor).double()\n",
    "        decoder = MLPDecoder(d1 * x_dims,\n",
    "                              z_dims, x_dims, encoder,\n",
    "                              data_variable_size = d1,\n",
    "                              batch_size = batch_size,\n",
    "                              n_hid=decoder_hidden,\n",
    "                              do_prob=decoder_dropout).double()\n",
    "\n",
    "        # ----------- Set up optimizer:\n",
    "        optimizer = optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr = original_lr)\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size = lr_decay,\n",
    "                                      gamma = gamma)\n",
    "\n",
    "        rel_rec = Variable(rel_rec)\n",
    "        rel_send = Variable(rel_send)\n",
    "\n",
    "        # ----------- Main:\n",
    "        best_ELBO_loss = np.inf\n",
    "        best_NLL_loss = np.inf\n",
    "        best_MSE_loss = np.inf\n",
    "        h1_B_new = 1 #torch.tensor(1.)\n",
    "        h2_B_new = 1\n",
    "        h1_B_old = np.inf\n",
    "        h2_B_old = np.inf\n",
    "        lr = original_lr\n",
    "\n",
    "        try:\n",
    "          for step_k in range(k_max_iter):\n",
    "              while c_B * d_B < 1e+20:\n",
    "                  for epoch in range(epochs):\n",
    "                      old_lr = lr \n",
    "                      ELBO_loss, NLL_loss, MSE_loss, origin_B, optimizer, lr = train_new(epoch, lambda1, c_B, lambda2, d_B, optimizer, old_lr,p=p,k=k)\n",
    "\n",
    "                      if ELBO_loss < best_ELBO_loss:\n",
    "                          best_ELBO_loss = ELBO_loss\n",
    "\n",
    "                      if NLL_loss < best_NLL_loss:\n",
    "                          best_NLL_loss = NLL_loss\n",
    "\n",
    "                      if MSE_loss < best_MSE_loss:\n",
    "                          best_MSE_loss = MSE_loss\n",
    "\n",
    "                  if ELBO_loss > 2 * best_ELBO_loss:\n",
    "                      break\n",
    "\n",
    "                  # Update parameters\n",
    "                  B_new = origin_B.data.clone()\n",
    "                  #h1_B = fun_h1_B(B_new[p:,p:]) #acyclity on G\n",
    "                  h1_B=0 \n",
    "                  for i in range(n_timestamp):\n",
    "                      #aa=h1_B+fun_h1_B(torch.matmul(spl_consraint(spline_list,i,p),B_new[p:,:p]))#acyclity on Gamma\n",
    "                      #print(aa)\n",
    "                      output, identity=spl_consraint(spline_list,i,p)\n",
    "                      h1_B=h1_B+fun_h1_B(torch.matmul(identity.type(torch.FloatTensor),(output.type(torch.FloatTensor)*B_new[p:,:p].type(torch.FloatTensor))))\n",
    "                      #h1_B=h1_B+fun_h1_B(torch.matmul(spl_consraint(spline_list,i,p).type(torch.FloatTensor),B_new[p:,:p].type(torch.FloatTensor)))#acyclity on Gamma\n",
    "                  h2_B = fun_h2_B_new(B_new) ##handle the zero on gamma and top\n",
    "                  #B_trans_new=torch.transpose(B_new, 0, 1)\n",
    "                  #h1_B = fun_h1_B(B_trans_new[p:,p:]) #acyclity on G\n",
    "                  #h1_B = fun_h1_B(B_new[p:,:p]) #edited acyclity on G\n",
    "                  #h2_B = fun_h3_B(B_new) ##handle the zero\n",
    "\n",
    "                  if h1_B_new > 0.25 * h1_B_old and h2_B_new > 0.25 * h2_B_old:\n",
    "                      c_B *= 10\n",
    "                      d_B *= 10\n",
    "                  elif h1_B_new > 0.25 * h1_B_old and h2_B_new < 0.25 * h2_B_old:\n",
    "                      c_B *= 10\n",
    "                  elif h1_B_new < 0.25 * h1_B_old and h2_B_new > 0.25 * h2_B_old:\n",
    "                      d_B *= 10\n",
    "                  else:\n",
    "                      break\n",
    "\n",
    "              # Update parameters    \n",
    "              h1_B_old = h1_B_new\n",
    "              h2_B_old = h2_B_new\n",
    "              lambda1 += c_B * h1_B_new\n",
    "              lambda2 += d_B * h2_B_new\n",
    "\n",
    "              if h1_B_new <= h1_tol and h2_B_new <= h2_tol:\n",
    "                  break\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "          print('KeyboardInterrupt')\n",
    "\n",
    "        predB = np.matrix(origin_B.data.clone().numpy())\n",
    "        pred_gamma=predB[p:,:(p)]\n",
    "        lambda_list[fold,::]=pred_gamma\n",
    "        np.save((\"full_10_30_gamma_basis_new\"+str(knots)),lambda_list)\n",
    "        \n",
    "        ELBO_total_new.append(best_ELBO_loss)\n",
    "        NLL_total_new.append(best_NLL_loss)\n",
    "        MSE_total_new.append(best_MSE_loss)\n",
    "        \n",
    "        timeend_new=time.time()\n",
    "        time_list_new.append(timeend_new-timestart_new)\n",
    "        print(timeend_new-timestart_new)\n",
    "        \n",
    "        ###print valid loss\n",
    "        nll_valid = []\n",
    "        kl_valid = []\n",
    "        mse_valid = []\n",
    "\n",
    "        for batch_idx, (data, relations) in enumerate(valid_loader):\n",
    "\n",
    "            data, relations = Variable(data).double(), Variable(relations).double()\n",
    "            relations = relations.unsqueeze(2) # Reshape data\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            enc_x, logits, origin_B, adj_A_tilt_encoder, z_gap, z_positive, myA, Wa = encoder(data, rel_rec, rel_send) \n",
    "            edges = logits # Logits is of size: [num_sims, z_dims]\n",
    "\n",
    "            dec_x, output, adj_A_tilt_decoder = decoder(data, edges, d * x_dims, rel_rec, rel_send, origin_B, adj_A_tilt_encoder, Wa)\n",
    "\n",
    "            if torch.sum(output != output):\n",
    "                print('nan error\\n')\n",
    "\n",
    "            target = data\n",
    "            preds = output\n",
    "            variance = 0.\n",
    "            \n",
    "            \n",
    "            loss_nll = nll_gaussian(preds, target, variance)\n",
    "            # KL loss:\n",
    "            loss_kl = kl_gaussian(logits)\n",
    "            # ELBO loss:\n",
    "            loss = loss_kl + loss_nll\n",
    "\n",
    "            mse_valid.append(F.mse_loss(preds, target).item())\n",
    "            nll_valid.append(loss_nll.item())\n",
    "            kl_valid.append(loss_kl.item())\n",
    "        ELBO_valid_new.append(mean(mse_valid))\n",
    "        NLL_valid_new.append(mean(nll_valid))\n",
    "        MSE_valid_new.append(mean(kl_valid))\n",
    "        print(\"mse_valid:\",mean(mse_valid),\"nll_valid:\",mean(nll_valid),\"kl_valid:\",mean(kl_valid))\n",
    "            \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2fc361d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.DataFrame(columns=('ELBO', 'NLL',\"MSE\",\"time\"))\n",
    "df_new[\"ELBO\"]=ELBO_total_new\n",
    "df_new[\"NLL\"]=NLL_total_new\n",
    "df_new[\"MSE\"]=MSE_total_new\n",
    "df_new[\"time\"]=time_list_new\n",
    "df_new\n",
    "df_new.to_csv(\"full_new_5_basis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1c7f27d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ELBO</th>\n",
       "      <th>NLL</th>\n",
       "      <th>MSE</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000300</td>\n",
       "      <td>8.455001e-07</td>\n",
       "      <td>6.764001e-08</td>\n",
       "      <td>2154.460098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000366</td>\n",
       "      <td>7.060223e-07</td>\n",
       "      <td>4.706815e-08</td>\n",
       "      <td>2201.758183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000329</td>\n",
       "      <td>1.227910e-06</td>\n",
       "      <td>7.016631e-08</td>\n",
       "      <td>2615.736651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000423</td>\n",
       "      <td>2.382649e-06</td>\n",
       "      <td>1.191325e-07</td>\n",
       "      <td>2656.447520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000336</td>\n",
       "      <td>1.396765e-06</td>\n",
       "      <td>6.207843e-08</td>\n",
       "      <td>2958.432893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ELBO           NLL           MSE         time\n",
       "0  0.000300  8.455001e-07  6.764001e-08  2154.460098\n",
       "1  0.000366  7.060223e-07  4.706815e-08  2201.758183\n",
       "2  0.000329  1.227910e-06  7.016631e-08  2615.736651\n",
       "3  0.000423  2.382649e-06  1.191325e-07  2656.447520\n",
       "4  0.000336  1.396765e-06  6.207843e-08  2958.432893"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.groupby(np.arange(len(df_new))//5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6d8725ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.DataFrame(columns=('ELBO', 'NLL',\"MSE\",\"time\"))\n",
    "df_new[\"ELBO\"]=ELBO_valid_new\n",
    "df_new[\"NLL\"]=NLL_valid_new\n",
    "df_new[\"MSE\"]=MSE_valid_new\n",
    "df_new\n",
    "df_new.to_csv(\"full_new_5_basis_valid.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f0d687ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ELBO</th>\n",
       "      <th>NLL</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>0.000364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ELBO       NLL       MSE\n",
       "0  0.000006  0.000077  0.000298\n",
       "1  0.000013  0.000190  0.000364\n",
       "2  0.000001  0.000018  0.000325\n",
       "3  0.000001  0.000022  0.000420\n",
       "4  0.000002  0.000036  0.000332"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.groupby(np.arange(len(df_new))//5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5255e6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "af937222",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "af937222",
    "outputId": "e80610dd-84e9-4b89-dce3-cc71ee027097"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.         -1.         -0.          0.88        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.97320508]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.795  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.9  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.72  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "[[ 0.    -1.    -0.     0.655  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.6         0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.555  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.6  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.52        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.495  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.48  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "(300, 35, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ELBO Loss : 0.0004776863893154498\n",
      "Best NLL Loss : 7.005861711653826e-07\n",
      "Best MSE Loss : 4.003349549516473e-08\n",
      "0\n",
      "[[ 0.         -1.         -0.          0.88        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.97320508]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.795  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.9  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.72  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "[[ 0.    -1.    -0.     0.655  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.6         0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.555  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.6  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.52        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.495  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.48  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "(300, 35, 1)\n",
      "Best ELBO Loss : 0.0008312651237082389\n",
      "Best NLL Loss : 2.2944199356125618e-05\n",
      "Best MSE Loss : 1.3110971060643206e-06\n",
      "1\n",
      "[[ 0.         -1.         -0.          0.88        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.97320508]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.795  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.9  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.72  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "[[ 0.    -1.    -0.     0.655  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.6         0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.555  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.6  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.52        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.495  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.48  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "(300, 35, 1)\n",
      "Best ELBO Loss : 0.0004379212079381833\n",
      "Best NLL Loss : 1.2397977776529672e-06\n",
      "Best MSE Loss : 7.084558729445528e-08\n",
      "2\n",
      "[[ 0.         -1.         -0.          0.88        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.97320508]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.795  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.9  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.72  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "[[ 0.    -1.    -0.     0.655  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.6         0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.555  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.6  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.52        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.495  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.48  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "(300, 35, 1)\n",
      "Best ELBO Loss : 0.0004782456035145133\n",
      "Best NLL Loss : 1.0159549576035598e-05\n",
      "Best MSE Loss : 5.805456900591771e-07\n",
      "3\n",
      "[[ 0.         -1.         -0.          0.88        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.97320508]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.795  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.9  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.72  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "[[ 0.    -1.    -0.     0.655  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.6         0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.555  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.6  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.52        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.495  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.48  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "(300, 35, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ELBO Loss : 0.0004705567344725719\n",
      "Best NLL Loss : 9.117112515301907e-07\n",
      "Best MSE Loss : 5.2097785801725164e-08\n",
      "4\n",
      "[[ 0.         -1.         -0.          0.88        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.97320508]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.795  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.9  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.72  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "[[ 0.    -1.    -0.     0.655  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.6         0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.555  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.6  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.52        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.495  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.48  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "(300, 35, 1)\n",
      "Best ELBO Loss : 0.00043294695410424475\n",
      "Best NLL Loss : 9.093543881815847e-08\n",
      "Best MSE Loss : 5.1963107896090536e-09\n",
      "5\n",
      "[[ 0.         -1.         -0.          0.88        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.97320508]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.795  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.9  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.72  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "[[ 0.    -1.    -0.     0.655  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.6         0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.555  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.6  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.52        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.495  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.48  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "(300, 35, 1)\n",
      "Best ELBO Loss : 0.000423483812279168\n",
      "Best NLL Loss : 1.3562976884883947e-06\n",
      "Best MSE Loss : 7.750272505647969e-08\n",
      "6\n",
      "[[ 0.         -1.         -0.          0.88        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.97320508]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.795  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.9  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.72  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "[[ 0.    -1.    -0.     0.655  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.6         0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.555  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.6  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.52        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.495  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.48  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "(300, 35, 1)\n",
      "Best ELBO Loss : 0.000450748783785093\n",
      "Best NLL Loss : 6.472827448820665e-07\n",
      "Best MSE Loss : 3.6987585421832344e-08\n",
      "7\n",
      "[[ 0.         -1.         -0.          0.88        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.97320508]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.795  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.9  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.72  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "[[ 0.    -1.    -0.     0.655  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.6         0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.555  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.6  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.52        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.495  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.48  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "(300, 35, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ELBO Loss : 0.00045349797897385584\n",
      "Best NLL Loss : 2.2263643431775164e-06\n",
      "Best MSE Loss : 1.272208196101438e-07\n",
      "8\n",
      "[[ 0.         -1.         -0.          0.88        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.97320508]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.795  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.9  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.72  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "[[ 0.    -1.    -0.     0.655  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.6         0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.555  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.6  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.52        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.495  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.48  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "(300, 35, 1)\n",
      "Best ELBO Loss : 0.0004940221097077408\n",
      "Best NLL Loss : 2.9620385464846045e-06\n",
      "Best MSE Loss : 1.6925934551340594e-07\n",
      "9\n",
      "[[ 0.         -1.         -0.          0.88        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.97320508]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.795  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.9  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.72  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "[[ 0.    -1.    -0.     0.655  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.6         0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.555  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.6  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.52        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.495  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.48  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "(300, 35, 1)\n",
      "Best ELBO Loss : 0.0004687555275151463\n",
      "Best NLL Loss : 7.468535450681817e-06\n",
      "Best MSE Loss : 4.2677345432467534e-07\n",
      "10\n",
      "[[ 0.         -1.         -0.          0.88        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.97320508]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.795  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.9  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.72  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "[[ 0.    -1.    -0.     0.655  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.6         0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.555  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.6  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.52        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.495  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.48  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "(300, 35, 1)\n",
      "Best ELBO Loss : 0.0005697567105991898\n",
      "Best NLL Loss : 6.473000208470819e-06\n",
      "Best MSE Loss : 3.698857261983326e-07\n",
      "11\n",
      "[[ 0.         -1.         -0.          0.88        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.97320508]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.795  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.9  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.72  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "[[ 0.    -1.    -0.     0.655  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.6         0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.555  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.6  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.52        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.495  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.48  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "(300, 35, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ELBO Loss : 0.0007178084396707768\n",
      "Best NLL Loss : 2.8424286998659217e-05\n",
      "Best MSE Loss : 1.6242449713519556e-06\n",
      "12\n",
      "[[ 0.         -1.         -0.          0.88        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.97320508]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.795  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.9  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.72  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "[[ 0.    -1.    -0.     0.655  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.6         0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.555  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.6  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.52        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.495  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.48  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "(300, 35, 1)\n",
      "Best ELBO Loss : 0.0007125373620630662\n",
      "Best NLL Loss : 1.1181718274907825e-05\n",
      "Best MSE Loss : 6.389553299947331e-07\n",
      "13\n",
      "[[ 0.         -1.         -0.          0.88        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.97320508]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.795  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.9  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.72  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "[[ 0.    -1.    -0.     0.655  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.6         0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.555  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.6  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.52        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.495  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.48  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "(300, 35, 1)\n",
      "Best ELBO Loss : 0.0004273114819440543\n",
      "Best NLL Loss : 1.0261537943357178e-06\n",
      "Best MSE Loss : 5.863735967632671e-08\n",
      "14\n",
      "[[ 0.         -1.         -0.          0.88        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.97320508]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.795  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.9  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.72  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "[[ 0.    -1.    -0.     0.655  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.6         0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.555  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.6  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.52        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.495  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.48  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "(300, 35, 1)\n",
      "Best ELBO Loss : 0.0003892709681964119\n",
      "Best NLL Loss : 1.8113295469107926e-07\n",
      "Best MSE Loss : 1.0350454553775967e-08\n",
      "15\n",
      "[[ 0.         -1.         -0.          0.88        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.97320508]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.795  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.9  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.72  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "[[ 0.    -1.    -0.     0.655  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.6         0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.555  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.6  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.52        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.495  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.48  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "(300, 35, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ELBO Loss : 0.0007470046888813739\n",
      "Best NLL Loss : 2.400400593038276e-05\n",
      "Best MSE Loss : 1.3716574817361578e-06\n",
      "16\n",
      "[[ 0.         -1.         -0.          0.88        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.97320508]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.795  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.9  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.72  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "[[ 0.    -1.    -0.     0.655  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.6         0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.555  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.6  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.52        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.495  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.48  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "(300, 35, 1)\n",
      "Best ELBO Loss : 0.00048360008125636274\n",
      "Best NLL Loss : 2.373844913565264e-06\n",
      "Best MSE Loss : 1.356482807751579e-07\n",
      "17\n",
      "[[ 0.         -1.         -0.          0.88        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.97320508]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.795  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.9  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.72  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "[[ 0.    -1.    -0.     0.655  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.6         0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.555  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.6  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.52        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.495  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.48  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "(300, 35, 1)\n",
      "Best ELBO Loss : 0.0004639101675355009\n",
      "Best NLL Loss : 3.427719116097236e-06\n",
      "Best MSE Loss : 1.9586966377698493e-07\n",
      "18\n",
      "[[ 0.         -1.         -0.          0.88        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.97320508]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.795  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.9  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.72  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "[[ 0.    -1.    -0.     0.655  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.6         0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.555  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.6  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.52        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.495  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.48  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "(300, 35, 1)\n",
      "Best ELBO Loss : 0.0007074035902300209\n",
      "Best NLL Loss : 1.0384300174179652e-05\n",
      "Best MSE Loss : 5.933885813816949e-07\n",
      "19\n",
      "[[ 0.         -1.         -0.          0.88        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.97320508]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.795  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.9  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.72  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "[[ 0.    -1.    -0.     0.655  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.6         0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.555  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.6  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.52        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.495  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.48  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "(300, 35, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ELBO Loss : 0.0005697077075571787\n",
      "Best NLL Loss : 5.260044159555958e-06\n",
      "Best MSE Loss : 3.0057395197462616e-07\n",
      "20\n",
      "[[ 0.         -1.         -0.          0.88        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.97320508]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.795  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.9  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.72  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "[[ 0.    -1.    -0.     0.655  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.6         0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.555  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.6  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.52        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.495  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.48  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "(300, 35, 1)\n",
      "Best ELBO Loss : 0.00047267107886537265\n",
      "Best NLL Loss : 5.134825953737372e-07\n",
      "Best MSE Loss : 2.9341862592784985e-08\n",
      "21\n",
      "[[ 0.         -1.         -0.          0.88        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.97320508]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.795  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.9  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.72  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "[[ 0.    -1.    -0.     0.655  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.6         0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.555  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.6  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.52        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.495  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.48  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "(300, 35, 1)\n",
      "Best ELBO Loss : 0.0004608258579519729\n",
      "Best NLL Loss : 2.0873685989042442e-07\n",
      "Best MSE Loss : 1.1927820565167118e-08\n",
      "22\n",
      "[[ 0.         -1.         -0.          0.88        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.97320508]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.795  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.9  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.72  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "[[ 0.    -1.    -0.     0.655  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.6         0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.555  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.6  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.52        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.495  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.48  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "(300, 35, 1)\n",
      "Best ELBO Loss : 0.0006081390823406789\n",
      "Best NLL Loss : 2.1686335407081275e-05\n",
      "Best MSE Loss : 1.23921916611893e-06\n",
      "23\n",
      "[[ 0.         -1.         -0.          0.88        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.97320508]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.795  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.9  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.72  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "[[ 0.    -1.    -0.     0.655  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.6         0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.555  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.6  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.52        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.495  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.48  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "(300, 35, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ELBO Loss : 0.0005676777683500656\n",
      "Best NLL Loss : 3.2273471420171475e-06\n",
      "Best MSE Loss : 1.8441983668669413e-07\n",
      "24\n",
      "[[ 0.         -1.         -0.          0.88        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.97320508]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.795  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.9  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.72  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "[[ 0.    -1.    -0.     0.655  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.6         0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.555  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.6  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.52        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.495  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.48  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "(300, 35, 1)\n",
      "Best ELBO Loss : 0.0007648045921908191\n",
      "Best NLL Loss : 1.0186727387365552e-05\n",
      "Best MSE Loss : 5.820987078494599e-07\n",
      "25\n",
      "[[ 0.         -1.         -0.          0.88        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.97320508]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.795  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.9  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.72  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "[[ 0.    -1.    -0.     0.655  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.6         0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.555  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.6  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.52        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.495  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.48  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "(300, 35, 1)\n",
      "Best ELBO Loss : 0.000562365096114381\n",
      "Best NLL Loss : 2.7191876924778396e-06\n",
      "Best MSE Loss : 1.5538215385587656e-07\n",
      "26\n",
      "[[ 0.         -1.         -0.          0.88        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.97320508]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.795  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.9  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.72  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "[[ 0.    -1.    -0.     0.655  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.6         0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.555  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.6  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.52        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.495  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.48  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "(300, 35, 1)\n",
      "Best ELBO Loss : 0.0005113649098826295\n",
      "Best NLL Loss : 5.324672823762066e-07\n",
      "Best MSE Loss : 3.042670185006894e-08\n",
      "27\n",
      "[[ 0.         -1.         -0.          0.88        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.97320508]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.795  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.9  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.72  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "[[ 0.    -1.    -0.     0.655  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.6         0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.555  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.6  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.52        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.495  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.48  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "(300, 35, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ELBO Loss : 0.0005162463817446125\n",
      "Best NLL Loss : 1.56559297583284e-06\n",
      "Best MSE Loss : 8.946245576187656e-08\n",
      "28\n",
      "[[ 0.         -1.         -0.          0.88        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.97320508]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.795  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.9  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.72  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "[[ 0.    -1.    -0.     0.655  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.6         0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.555  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.6  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.52        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.495  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.48  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "(300, 35, 1)\n",
      "Best ELBO Loss : 0.00040685210825626824\n",
      "Best NLL Loss : 2.7643917304145706e-06\n",
      "Best MSE Loss : 1.5796524173797547e-07\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "n_var=5\n",
    "n_times=30 #no. of replicates\n",
    "time_stamp=10 #no. of timestamp\n",
    "np.random.seed(1234567) #Random seed\n",
    "#seed_list=np.random.randint(1, 1000000, size=n_times)\n",
    "average_coef_list_new=np.zeros((n_times,time_stamp,n_var,n_var))\n",
    "FDR_total_new=[]\n",
    "TPR_total_new=[]\n",
    "SHD_total_new=[]\n",
    "time_list_new=[]\n",
    "for replicate in range(n_times):\n",
    "  seed=seed_list[replicate]\n",
    "  X_all=data_create(seed,time_stamp,base_DAG) #create data\n",
    "  D=create_D(X_all,spline_list)\n",
    "  data_all=np.append(X_all,D, axis=1)\n",
    "  print(np.shape(data_all))\n",
    "  average_list=np.zeros((time_stamp,n_var, n_var))\n",
    "  ####estimate at each time_stamp####\n",
    "  timestart_new=time.time()\n",
    "    # ----------- Configurations:\n",
    "  # ----------- Configurations:\n",
    "  n = 30*time_stamp # The number of samples of data.\n",
    "  d = 36 # The number of variables in data after basis.\n",
    "  x_dims = 1 # The number of input dimensions: default 1.\n",
    "  z_dims = d # The number of latent variable dimensions: default the same as variable size.\n",
    "  epochs = 200 # Number of epochs to train.\n",
    "  batch_size = 10 # Number of samples per batch. note: should be divisible by sample size, otherwise throw an error.\n",
    "  k_max_iter = int(1e2) # The max iteration number for searching parameters.\n",
    "  original_lr = 3e-3  # Initial learning rate.\n",
    "  encoder_hidden = d^2 # Number of hidden units, adaptive to dimension of nodes (d^2).\n",
    "  decoder_hidden = d^2 # Number of hidden units, adaptive to dimension of nodes (d^2).\n",
    "  temp = 0.5 # Temperature for Gumbel softmax.\n",
    "  factor = True # Factor graph model.\n",
    "  encoder_dropout = 0.0 # Dropout rate (1 - keep probability).\n",
    "  decoder_dropout = 0.0 # Dropout rate (1 - keep probability).\n",
    "  tau_B = 0. # Coefficient for L-1 norm of matrix B.\n",
    "  lambda1 = 0. # Coefficient for DAG constraint h1(B).\n",
    "  lambda2 = 0. # Coefficient for identification constraint h2(B).\n",
    "  c_B = 1 # Coefficient for absolute value h1(B).\n",
    "  d_B = 1 # Coefficient for absolute value h2(B).\n",
    "  e_B = 1 # Coefficient for absolute value h3(B)\n",
    "  h1_tol = 1e-8 # The tolerance of error of h1(B) to zero.\n",
    "  h2_tol = 1e-8 # The tolerance of error of h2(B) to zero.\n",
    "  h3_tol = 1e-8 # The tolerance of error of h2(B) to zero.\n",
    "  lr_decay = 200 # After how many epochs to decay LR by a factor of gamma. \n",
    "  gamma = 1.0 # LR decay factor.  \n",
    "    ######################\n",
    "  p=5\n",
    "  k=6 #no.of basis\n",
    "  np.random.seed(seed)\n",
    "  random.seed(seed)\n",
    "  torch.manual_seed(seed)\n",
    "  feat_train = torch.FloatTensor(data_all)\n",
    "  feat_valid = torch.FloatTensor(data_all)\n",
    "  feat_test = torch.FloatTensor(data_all)\n",
    "\n",
    "  # Reconstruct itself\n",
    "  train_data = TensorDataset(feat_train, feat_train)\n",
    "  valid_data = TensorDataset(feat_valid, feat_train)\n",
    "  test_data = TensorDataset(feat_test, feat_train)\n",
    "\n",
    "  train_loader = DataLoader(train_data, batch_size = batch_size)\n",
    "  valid_loader = DataLoader(valid_data, batch_size = batch_size)\n",
    "  test_loader = DataLoader(test_data, batch_size = batch_size)\n",
    "\n",
    "  # ----------- Load modules:\n",
    "  d1=p+p*k\n",
    "  off_diag = np.ones([d1, d1]) - np.eye(d1) # Generate off-diagonal interaction graph\n",
    "  rel_rec = np.array(encode_onehot(np.where(off_diag)[1]), dtype = np.float64)\n",
    "  rel_send = np.array(encode_onehot(np.where(off_diag)[0]), dtype = np.float64)\n",
    "  rel_rec = torch.DoubleTensor(rel_rec)\n",
    "  rel_send = torch.DoubleTensor(rel_send)\n",
    "  adj_A = np.zeros((d1, d1)) # Add adjacency matrix\n",
    "\n",
    "  encoder = MLPEncoder(d1 * x_dims, x_dims, encoder_hidden,\n",
    "                          int(z_dims), adj_A,\n",
    "                          batch_size = batch_size,\n",
    "                          do_prob = encoder_dropout, factor = factor).double()\n",
    "  decoder = MLPDecoder(d1 * x_dims,\n",
    "                          z_dims, x_dims, encoder,\n",
    "                          data_variable_size = d1,\n",
    "                          batch_size = batch_size,\n",
    "                          n_hid=decoder_hidden,\n",
    "                          do_prob=decoder_dropout).double()\n",
    "\n",
    "  # ----------- Set up optimizer:\n",
    "  optimizer = optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr = original_lr)\n",
    "  scheduler = lr_scheduler.StepLR(optimizer, step_size = lr_decay,\n",
    "                                  gamma = gamma)\n",
    "\n",
    "  rel_rec = Variable(rel_rec)\n",
    "  rel_send = Variable(rel_send)\n",
    "\n",
    "  # ----------- Main:\n",
    "  best_ELBO_loss = np.inf\n",
    "  best_NLL_loss = np.inf\n",
    "  best_MSE_loss = np.inf\n",
    "  h1_B_new = 1 #torch.tensor(1.)\n",
    "  h2_B_new = 1\n",
    "  h1_B_old = np.inf\n",
    "  h2_B_old = np.inf\n",
    "  lr = original_lr\n",
    "\n",
    "  try:\n",
    "      for step_k in range(k_max_iter):\n",
    "          while c_B * d_B < 1e+20:\n",
    "              for epoch in range(epochs):\n",
    "                  old_lr = lr \n",
    "                  ELBO_loss, NLL_loss, MSE_loss, origin_B, optimizer, lr = train_new(epoch, lambda1, c_B, lambda2, d_B, optimizer, old_lr,p=p,k=k)\n",
    "\n",
    "                  if ELBO_loss < best_ELBO_loss:\n",
    "                      best_ELBO_loss = ELBO_loss\n",
    "\n",
    "                  if NLL_loss < best_NLL_loss:\n",
    "                      best_NLL_loss = NLL_loss\n",
    "\n",
    "                  if MSE_loss < best_MSE_loss:\n",
    "                      best_MSE_loss = MSE_loss\n",
    "\n",
    "              if ELBO_loss > 2 * best_ELBO_loss:\n",
    "                  break\n",
    "\n",
    "              # Update parameters\n",
    "              B_new = origin_B.data.clone()\n",
    "              #h1_B = fun_h1_B(B_new[p:,p:]) #acyclity on G\n",
    "              h1_B=0 \n",
    "              for i in range(n_timestamp):\n",
    "                  #aa=h1_B+fun_h1_B(torch.matmul(spl_consraint(spline_list,i,p),B_new[p:,:p]))#acyclity on Gamma\n",
    "                  #print(aa)\n",
    "                  output, identity=spl_consraint(spline_list,i,p)\n",
    "                  h1_B=h1_B+fun_h1_B(torch.matmul(identity.type(torch.FloatTensor),(output.type(torch.FloatTensor)*B_new[p:,:p].type(torch.FloatTensor))))\n",
    "                  #h1_B=h1_B+fun_h1_B(torch.matmul(spl_consraint(spline_list,i,p).type(torch.FloatTensor),B_new[p:,:p].type(torch.FloatTensor)))#acyclity on Gamma\n",
    "              h2_B = fun_h2_B_new(B_new) ##handle the zero on gamma and top\n",
    "              #B_trans_new=torch.transpose(B_new, 0, 1)\n",
    "              #h1_B = fun_h1_B(B_trans_new[p:,p:]) #acyclity on G\n",
    "              #h1_B = fun_h1_B(B_new[p:,:p]) #edited acyclity on G\n",
    "              #h2_B = fun_h3_B(B_new) ##handle the zero\n",
    "\n",
    "              if h1_B_new > 0.25 * h1_B_old and h2_B_new > 0.25 * h2_B_old:\n",
    "                  c_B *= 10\n",
    "                  d_B *= 10\n",
    "              elif h1_B_new > 0.25 * h1_B_old and h2_B_new < 0.25 * h2_B_old:\n",
    "                  c_B *= 10\n",
    "              elif h1_B_new < 0.25 * h1_B_old and h2_B_new > 0.25 * h2_B_old:\n",
    "                  d_B *= 10\n",
    "              else:\n",
    "                  break\n",
    "\n",
    "          # Update parameters    \n",
    "          h1_B_old = h1_B_new\n",
    "          h2_B_old = h2_B_new\n",
    "          lambda1 += c_B * h1_B_new\n",
    "          lambda2 += d_B * h2_B_new\n",
    "\n",
    "          if h1_B_new <= h1_tol and h2_B_new <= h2_tol:\n",
    "              break\n",
    "\n",
    "  except KeyboardInterrupt:\n",
    "      print('KeyboardInterrupt')\n",
    "\n",
    "  predB = np.matrix(origin_B.data.clone().numpy())\n",
    "  print('Best ELBO Loss :', best_ELBO_loss)\n",
    "  print('Best NLL Loss :', best_NLL_loss)\n",
    "  print('Best MSE Loss :', best_MSE_loss)\n",
    "  #calculate_effect(predB)\n",
    "  pred_gamma=predB[p:,:(p)]\n",
    "  def matrix_gen(t):\n",
    "    output,identity=spl_consraint(spline_list,t,p)\n",
    "    return torch.matmul(identity.type(torch.FloatTensor),torch.from_numpy((np.multiply(output.numpy(),pred_gamma))).type(torch.FloatTensor)).T\n",
    "  #estimated_coefficient=[matrix_gen(i)[4,0].item() for i in range(time_stamp)]\n",
    "  #average_coef_list_new[replicate,:]=estimated_coefficient\n",
    "\n",
    "  ## FDR, TPR, SHD for  new method\n",
    "  FDR_list_piece_new=[]\n",
    "  TPR_list_piece_new=[]\n",
    "  SHD_list_piece_new=[]\n",
    "  #base_DAG=np.zeros((5, 5))\n",
    "  for i in range(time_stamp):\n",
    "      #base_DAG[0,4]=cos(i)\n",
    "      #base_DAG[2,3]=quadratic(j)\n",
    "      #base_DAG[3,4]=-1 ###constant\n",
    "      #base_DAG[2,4]=-1\n",
    "      #base_DAG[base_DAG<0.4]=0##change base_DAG\n",
    "     #FDR, TPR, SHD\n",
    "      #base_DAG[base_DAG<0.4] = 0 ##edited to remove the effect\n",
    "      base_graph=nx.from_numpy_matrix(base_DAG,create_using=nx.DiGraph)\n",
    "      average_coef_list_new[replicate,i,:,:]=matrix_gen(i).numpy()\n",
    "      a=matrix_gen(i).numpy()\n",
    "      a[abs(a)<0.3] = 0\n",
    "      base_estimate=nx.from_numpy_matrix(a.T,create_using=nx.DiGraph)\n",
    "    \n",
    "      FDR,TPR,SHD=count_accuracy(base_graph,base_estimate)\n",
    "      FDR_list_piece_new.append(FDR)\n",
    "      TPR_list_piece_new.append(TPR)\n",
    "      SHD_list_piece_new.append(SHD)\n",
    "  np.save(\"full_20_30\",average_coef_list_new)\n",
    "  FDR_total_new.append(mean(FDR_list_piece_new))\n",
    "  TPR_total_new.append(mean(TPR_list_piece_new))\n",
    "  SHD_total_new.append(mean(SHD_list_piece_new))\n",
    "  timeend_new=time.time()\n",
    "  time_list_new.append(timeend_new-timestart_new)\n",
    "  ###write csv\n",
    "  df_new = pd.DataFrame(columns=('FDR', 'TPR',\"SHD\",\"time\"))\n",
    "  df_new[\"FDR\"]=FDR_total_new\n",
    "  df_new[\"TPR\"]=TPR_total_new\n",
    "  df_new[\"SHD\"]=SHD_total_new\n",
    "  df_new[\"time\"]=time_list_new\n",
    "  #df_new.to_csv(\"cos_new_5.csv\")\n",
    "  print(replicate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a47f85e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([913812, 374400, 343669, 289095, 235846, 432099, 448097, 384097,\n",
       "       134030, 454991, 401627,  97188, 615884, 585262, 902641, 897795,\n",
       "       678150, 361884, 928159, 446640,  26580, 865407, 789523, 704840,\n",
       "       359269,  38248, 809111, 137636, 698530, 230177])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "acd28256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 10, 5, 5)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_coef_list_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b4b52598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.  , -1.  , -0.  ,  0.48,  0.  ],\n",
       "       [ 0.  ,  0.  ,  0.  ,  0.  , -0.  ],\n",
       "       [ 0.  ,  1.  , -0.  ,  0.  ,  0.8 ],\n",
       "       [ 0.  , -0.  ,  0.  ,  0.  , -0.  ],\n",
       "       [ 0.  ,  0.  ,  0.  ,  0.  ,  0.  ]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ef1d5c67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FDR</th>\n",
       "      <th>TPR</th>\n",
       "      <th>SHD</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.700</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3258.330431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3326.005435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.9</td>\n",
       "      <td>3513.402346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.650</td>\n",
       "      <td>1.4</td>\n",
       "      <td>4169.488957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.158333</td>\n",
       "      <td>0.525</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3877.003762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.475</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3563.864658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.675</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3894.198721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.450</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4116.859723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3770.608342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.425</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3720.932009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3424.223121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.085000</td>\n",
       "      <td>0.850</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3739.044957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.725</td>\n",
       "      <td>1.2</td>\n",
       "      <td>3422.535276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3431.669997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3747.574828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.085000</td>\n",
       "      <td>0.800</td>\n",
       "      <td>1.2</td>\n",
       "      <td>4034.962995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.9</td>\n",
       "      <td>3751.720391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.045000</td>\n",
       "      <td>0.750</td>\n",
       "      <td>1.2</td>\n",
       "      <td>3447.882591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>1.7</td>\n",
       "      <td>3459.637051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3605.758408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3627.625778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.725</td>\n",
       "      <td>1.1</td>\n",
       "      <td>3588.648622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.400</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3808.533686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3760.148748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.700</td>\n",
       "      <td>1.2</td>\n",
       "      <td>3428.540013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3284.113357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.675</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3179.393076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3102.638072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.775</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3716.544600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3146.493970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         FDR    TPR  SHD         time\n",
       "0   0.050000  0.700  1.4  3258.330431\n",
       "1   0.020000  0.825  0.8  3326.005435\n",
       "2   0.000000  0.775  0.9  3513.402346\n",
       "3   0.000000  0.650  1.4  4169.488957\n",
       "4   0.158333  0.525  2.4  3877.003762\n",
       "5   0.125000  0.475  2.5  3563.864658\n",
       "6   0.000000  0.675  1.3  3894.198721\n",
       "7   0.116667  0.450  2.5  4116.859723\n",
       "8   0.000000  0.800  0.8  3770.608342\n",
       "9   0.000000  0.425  2.3  3720.932009\n",
       "10  0.000000  0.625  1.5  3424.223121\n",
       "11  0.085000  0.850  1.0  3739.044957\n",
       "12  0.025000  0.725  1.2  3422.535276\n",
       "13  0.020000  0.875  0.6  3431.669997\n",
       "14  0.000000  0.850  0.6  3747.574828\n",
       "15  0.085000  0.800  1.2  4034.962995\n",
       "16  0.040000  0.825  0.9  3751.720391\n",
       "17  0.045000  0.750  1.2  3447.882591\n",
       "18  0.050000  0.625  1.7  3459.637051\n",
       "19  0.000000  0.900  0.4  3605.758408\n",
       "20  0.020000  0.900  0.5  3627.625778\n",
       "21  0.000000  0.725  1.1  3588.648622\n",
       "22  0.066667  0.400  2.6  3808.533686\n",
       "23  0.000000  0.850  0.6  3760.148748\n",
       "24  0.000000  0.700  1.2  3428.540013\n",
       "25  0.000000  0.825  0.7  3284.113357\n",
       "26  0.025000  0.675  1.4  3179.393076\n",
       "27  0.000000  0.750  1.0  3102.638072\n",
       "28  0.025000  0.775  1.0  3716.544600\n",
       "29  0.040000  0.875  0.7  3146.493970"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = pd.DataFrame(columns=('FDR', 'TPR',\"SHD\",\"time\"))\n",
    "df_new[\"FDR\"]=FDR_total_new\n",
    "df_new[\"TPR\"]=TPR_total_new\n",
    "df_new[\"SHD\"]=SHD_total_new\n",
    "df_new[\"time\"]=time_list_new\n",
    "\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "74c5dd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_new=np.load(\"result/full_20_30.npy\") #0 axis is the number of replicates\n",
    "result_ANOCA=np.load(\"result/full_20_30_ANOCA.npy\")\n",
    "result_NOTEARS=np.load(\"result/full_10_30_NOTEARS.npy\")\n",
    "result_dynotears=np.load(\"result/dynotears_full_w_noA.npy\")\n",
    "result_DAGGNN=np.load(\"result/S2_10_30_DAGGNN.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cece8df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total effect (TE): 0.0\n",
      "The natural direct effect (DE): 0.0\n",
      "The natural indirect effect (IE): 0.0\n",
      "The natural direct effect for mediators (DM): [ 0.  0. -0.]\n",
      "The natural direct effect for mediators (IM): [0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FDR    0.119389\n",
       "TPR    0.850833\n",
       "SHD    1.120000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#proposed\n",
    "np.random.seed(123456)\n",
    "base_DAG=simulate_random_dag(5,4)\n",
    "random.seed(1234567)\n",
    "pick_1=np.nonzero(base_DAG)[0][pick_element[0]],np.nonzero(base_DAG)[1][pick_element[0]]\n",
    "pick_2=np.nonzero(base_DAG)[0][pick_element[1]],np.nonzero(base_DAG)[1][pick_element[1]]\n",
    "FDR_total_new=[]\n",
    "TPR_total_new=[]\n",
    "SHD_total_new=[]\n",
    "for replicate in range(30):\n",
    "    FDR_list_piece_new=[]\n",
    "    TPR_list_piece_new=[]\n",
    "    SHD_list_piece_new=[]\n",
    "    for i in range(time_stamp):\n",
    "        base_DAG[pick_1]=cos(i)##edited to be coeffcient with error\n",
    "        base_DAG[pick_2]=quadratic(i)###multiple\n",
    "        base_DAG[abs(base_DAG)<0.2] = 0\n",
    "        base_graph=nx.from_numpy_matrix(base_DAG,create_using=nx.DiGraph)\n",
    "        a=result_new[replicate,i,:,:]\n",
    "        a[abs(a)<0.2] = 0\n",
    "        base_estimate=nx.from_numpy_matrix(a.T,create_using=nx.DiGraph)\n",
    "\n",
    "        FDR,TPR,SHD=count_accuracy(base_graph,base_estimate)\n",
    "        FDR_list_piece_new.append(FDR)\n",
    "        TPR_list_piece_new.append(TPR)\n",
    "        SHD_list_piece_new.append(SHD)\n",
    "    FDR_total_new.append(mean(FDR_list_piece_new))\n",
    "    TPR_total_new.append(mean(TPR_list_piece_new))\n",
    "    SHD_total_new.append(mean(SHD_list_piece_new))\n",
    "df_new = pd.DataFrame(columns=('FDR', 'TPR',\"SHD\"))\n",
    "df_new[\"FDR\"]=FDR_total_new\n",
    "df_new[\"TPR\"]=TPR_total_new\n",
    "df_new[\"SHD\"]=SHD_total_new\n",
    "#df_new[\"time\"]=time_list_new\n",
    "df_new.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a36d734d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FDR    0.010758\n",
       "TPR    0.021425\n",
       "SHD    0.106501\n",
       "dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.std()/np.sqrt(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5eb992cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total effect (TE): 0.0\n",
      "The natural direct effect (DE): 0.0\n",
      "The natural indirect effect (IE): 0.0\n",
      "The natural direct effect for mediators (DM): [ 0.  0. -0.]\n",
      "The natural direct effect for mediators (IM): [0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FDR    0.616124\n",
       "TPR    0.483333\n",
       "SHD    5.100000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DAGGNN\n",
    "np.random.seed(123456)\n",
    "base_DAG=simulate_random_dag(5,4)\n",
    "random.seed(1234567)\n",
    "pick_1=np.nonzero(base_DAG)[0][pick_element[0]],np.nonzero(base_DAG)[1][pick_element[0]]\n",
    "pick_2=np.nonzero(base_DAG)[0][pick_element[1]],np.nonzero(base_DAG)[1][pick_element[1]]\n",
    "FDR_total_new=[]\n",
    "TPR_total_new=[]\n",
    "SHD_total_new=[]\n",
    "for replicate in range(30):\n",
    "    FDR_list_piece_new=[]\n",
    "    TPR_list_piece_new=[]\n",
    "    SHD_list_piece_new=[]\n",
    "    for i in range(time_stamp):\n",
    "        base_DAG[pick_1]=cos(i)##edited to be coeffcient with error\n",
    "        base_DAG[pick_2]=quadratic(i)###multiple\n",
    "        base_DAG[abs(base_DAG)<0.2] = 0\n",
    "        base_graph=nx.from_numpy_matrix(base_DAG,create_using=nx.DiGraph)\n",
    "        a=result_DAGGNN[replicate,i,:,:]\n",
    "        a[abs(a)<0.2] = 0\n",
    "        base_estimate=nx.from_numpy_matrix(a.T,create_using=nx.DiGraph)\n",
    "\n",
    "        FDR,TPR,SHD=count_accuracy(base_graph,base_estimate)\n",
    "        FDR_list_piece_new.append(FDR)\n",
    "        TPR_list_piece_new.append(TPR)\n",
    "        SHD_list_piece_new.append(SHD)\n",
    "    FDR_total_new.append(mean(FDR_list_piece_new))\n",
    "    TPR_total_new.append(mean(TPR_list_piece_new))\n",
    "    SHD_total_new.append(mean(SHD_list_piece_new))\n",
    "df_new = pd.DataFrame(columns=('FDR', 'TPR',\"SHD\"))\n",
    "df_new[\"FDR\"]=FDR_total_new\n",
    "df_new[\"TPR\"]=TPR_total_new\n",
    "df_new[\"SHD\"]=SHD_total_new\n",
    "#df_new[\"time\"]=time_list_new\n",
    "df_new.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fe7c0e41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FDR    0.021153\n",
       "TPR    0.033513\n",
       "SHD    0.165045\n",
       "dtype: float64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.std()/np.sqrt(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4778de53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total effect (TE): 0.0\n",
      "The natural direct effect (DE): 0.0\n",
      "The natural indirect effect (IE): 0.0\n",
      "The natural direct effect for mediators (DM): [ 0.  0. -0.]\n",
      "The natural direct effect for mediators (IM): [0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FDR    0.358009\n",
       "TPR    0.835833\n",
       "SHD    2.826667\n",
       "dtype: float64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANOCA\n",
    "np.random.seed(123456)\n",
    "base_DAG=simulate_random_dag(5,4)\n",
    "random.seed(1234567)\n",
    "pick_1=np.nonzero(base_DAG)[0][pick_element[0]],np.nonzero(base_DAG)[1][pick_element[0]]\n",
    "pick_2=np.nonzero(base_DAG)[0][pick_element[1]],np.nonzero(base_DAG)[1][pick_element[1]]\n",
    "FDR_total=[]\n",
    "TPR_total=[]\n",
    "SHD_total=[]\n",
    "for replicate in range(30):\n",
    "    FDR_list_piece=[]\n",
    "    TPR_list_piece=[]\n",
    "    SHD_list_piece=[]\n",
    "    for i in range(time_stamp):\n",
    "      base_DAG[pick_1]=cos(i)##edited to be coeffcient with error\n",
    "      base_DAG[pick_2]=quadratic(i)###multiple\n",
    "      base_DAG[abs(base_DAG)<0.2]=0\n",
    "      base_graph=nx.from_numpy_matrix(base_DAG,create_using=nx.DiGraph)\n",
    "      a=result_ANOCA[replicate,i,:,:]\n",
    "      a[abs(a)<0.2] = 0\n",
    "      base_estimate=nx.from_numpy_matrix(a,create_using=nx.DiGraph)\n",
    "\n",
    "      FDR,TPR,SHD=count_accuracy(base_graph,base_estimate)\n",
    "      FDR_list_piece.append(FDR)\n",
    "      TPR_list_piece.append(TPR)\n",
    "      SHD_list_piece.append(SHD)\n",
    "    FDR_total.append(mean(FDR_list_piece))\n",
    "    TPR_total.append(mean(TPR_list_piece))\n",
    "    SHD_total.append(mean(SHD_list_piece))\n",
    "df = pd.DataFrame(columns=('FDR', 'TPR',\"SHD\"))\n",
    "df[\"FDR\"]=FDR_total\n",
    "df[\"TPR\"]=TPR_total\n",
    "df[\"SHD\"]=SHD_total\n",
    "#df_new[\"time\"]=time_list_new\n",
    "df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "993cb791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FDR    0.021153\n",
       "TPR    0.033513\n",
       "SHD    0.165045\n",
       "dtype: float64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.std()/np.sqrt(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c232de9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total effect (TE): 0.0\n",
      "The natural direct effect (DE): 0.0\n",
      "The natural indirect effect (IE): 0.0\n",
      "The natural direct effect for mediators (DM): [ 0.  0. -0.]\n",
      "The natural direct effect for mediators (IM): [0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FDR    0.501111\n",
       "TPR    0.251667\n",
       "SHD    3.026667\n",
       "dtype: float64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NOTEARS\n",
    "np.random.seed(123456)\n",
    "base_DAG=simulate_random_dag(5,4)\n",
    "random.seed(1234567)\n",
    "pick_1=np.nonzero(base_DAG)[0][pick_element[0]],np.nonzero(base_DAG)[1][pick_element[0]]\n",
    "pick_2=np.nonzero(base_DAG)[0][pick_element[1]],np.nonzero(base_DAG)[1][pick_element[1]]\n",
    "FDR_total_new=[]\n",
    "TPR_total_new=[]\n",
    "SHD_total_new=[]\n",
    "for replicate in range(30):\n",
    "    FDR_list_piece_new=[]\n",
    "    TPR_list_piece_new=[]\n",
    "    SHD_list_piece_new=[]\n",
    "    for i in range(time_stamp):\n",
    "        base_DAG[pick_1]=cos(i)##edited to be coeffcient with error\n",
    "        base_DAG[pick_2]=quadratic(i)###multiple\n",
    "        base_DAG[abs(base_DAG)<0.2] = 0\n",
    "        base_graph=nx.from_numpy_matrix(base_DAG,create_using=nx.DiGraph)\n",
    "        a=result_NOTEARS[replicate,i,:,:]\n",
    "        a[abs(a)<0.2] = 0\n",
    "        base_estimate=nx.from_numpy_matrix(a.T,create_using=nx.DiGraph)\n",
    "\n",
    "        FDR,TPR,SHD=count_accuracy(base_graph,base_estimate)\n",
    "        FDR_list_piece_new.append(FDR)\n",
    "        TPR_list_piece_new.append(TPR)\n",
    "        SHD_list_piece_new.append(SHD)\n",
    "    FDR_total_new.append(mean(FDR_list_piece_new))\n",
    "    TPR_total_new.append(mean(TPR_list_piece_new))\n",
    "    SHD_total_new.append(mean(SHD_list_piece_new))\n",
    "df_new = pd.DataFrame(columns=('FDR', 'TPR',\"SHD\"))\n",
    "df_new[\"FDR\"]=FDR_total_new\n",
    "df_new[\"TPR\"]=TPR_total_new\n",
    "df_new[\"SHD\"]=SHD_total_new\n",
    "#df_new[\"time\"]=time_list_new\n",
    "df_new.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ff32ab53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FDR    0.021153\n",
       "TPR    0.033513\n",
       "SHD    0.165045\n",
       "dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.std()/np.sqrt(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6e913899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total effect (TE): 0.0\n",
      "The natural direct effect (DE): 0.0\n",
      "The natural indirect effect (IE): 0.0\n",
      "The natural direct effect for mediators (DM): [ 0.  0. -0.]\n",
      "The natural direct effect for mediators (IM): [0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FDR    0.502469\n",
       "TPR    0.250000\n",
       "SHD    3.029630\n",
       "dtype: float64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DYNOTEARS\n",
    "np.random.seed(123456)\n",
    "base_DAG=simulate_random_dag(5,4)\n",
    "random.seed(1234567)\n",
    "pick_1=np.nonzero(base_DAG)[0][pick_element[0]],np.nonzero(base_DAG)[1][pick_element[0]]\n",
    "pick_2=np.nonzero(base_DAG)[0][pick_element[1]],np.nonzero(base_DAG)[1][pick_element[1]]\n",
    "FDR_total_new=[]\n",
    "TPR_total_new=[]\n",
    "SHD_total_new=[]\n",
    "for replicate in range(30):\n",
    "    FDR_list_piece_new=[]\n",
    "    TPR_list_piece_new=[]\n",
    "    SHD_list_piece_new=[]\n",
    "    for i in range(time_stamp-1):\n",
    "        base_DAG[pick_1]=cos(i+1)##edited to be coeffcient with error\n",
    "        base_DAG[pick_2]=quadratic(i+1)###multiple\n",
    "        base_DAG[abs(base_DAG)<0.2] = 0\n",
    "        base_graph=nx.from_numpy_matrix(base_DAG,create_using=nx.DiGraph)\n",
    "        a=result_dynotears[replicate,i,:,:]\n",
    "        a[abs(a)<0.2] = 0\n",
    "        base_estimate=nx.from_numpy_matrix(a.T,create_using=nx.DiGraph)\n",
    "\n",
    "        FDR,TPR,SHD=count_accuracy(base_graph,base_estimate)\n",
    "        FDR_list_piece_new.append(FDR)\n",
    "        TPR_list_piece_new.append(TPR)\n",
    "        SHD_list_piece_new.append(SHD)\n",
    "    FDR_total_new.append(mean(FDR_list_piece_new))\n",
    "    TPR_total_new.append(mean(TPR_list_piece_new))\n",
    "    SHD_total_new.append(mean(SHD_list_piece_new))\n",
    "df_new = pd.DataFrame(columns=('FDR', 'TPR',\"SHD\"))\n",
    "df_new[\"FDR\"]=FDR_total_new\n",
    "df_new[\"TPR\"]=TPR_total_new\n",
    "df_new[\"SHD\"]=SHD_total_new\n",
    "#df_new[\"time\"]=time_list_new\n",
    "df_new.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "96bdc4cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FDR    0.001169\n",
       "TPR    0.000000\n",
       "SHD    0.009124\n",
       "dtype: float64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.std()/np.sqrt(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3632422f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total effect (TE): 0.0\n",
      "The natural direct effect (DE): 0.0\n",
      "The natural indirect effect (IE): 0.0\n",
      "The natural direct effect for mediators (DM): [ 0.  0. -0.]\n",
      "The natural direct effect for mediators (IM): [0. 0. 0.]\n",
      "The total effect (TE): 0.0\n",
      "The natural direct effect (DE): 0.0\n",
      "The natural indirect effect (IE): 0.0\n",
      "The natural direct effect for mediators (DM): [ 0.  0. -0.]\n",
      "The natural direct effect for mediators (IM): [0. 0. 0.]\n",
      "The total effect (TE): 0.0\n",
      "The natural direct effect (DE): 0.0\n",
      "The natural indirect effect (IE): 0.0\n",
      "The natural direct effect for mediators (DM): [ 0.  0. -0.]\n",
      "The natural direct effect for mediators (IM): [0. 0. 0.]\n",
      "The total effect (TE): 0.0\n",
      "The natural direct effect (DE): 0.0\n",
      "The natural indirect effect (IE): 0.0\n",
      "The natural direct effect for mediators (DM): [ 0.  0. -0.]\n",
      "The natural direct effect for mediators (IM): [0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x1152 with 24 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "select_time=[0,3,6,9]\n",
    "methods=[\"DAGGNN\",\"ANOCE\",\"NOTEARS\",\"DYNOTEARS\",\"Proposed\",\"TRUE\"]\n",
    "figure, axs = plt.subplots(nrows=len(methods), ncols=4, figsize=(12, 16))\n",
    "for i in range(len(select_time)):\n",
    "    actual_time=select_time[i]\n",
    "    #DAGGNN\n",
    "    DAGGNN_graph=result_DAGGNN[:,actual_time,:,:].mean(axis=0).T\n",
    "    DAGGNN_graph[abs(DAGGNN_graph)<0.2]=0\n",
    "    axs[0, i].matshow(DAGGNN_graph, cmap = 'bwr', vmin = -1, vmax = 1)\n",
    "    axs[0, i].set_title(str((select_time[i])),fontdict={'fontsize': 20})\n",
    "    ##ANOCA\n",
    "    ANOCA_graph=result_ANOCA[:,actual_time,:,:].mean(axis=0)\n",
    "    ANOCA_graph[abs(ANOCA_graph)<0.2]=0\n",
    "    axs[1, i].matshow(ANOCA_graph, cmap = 'bwr', vmin = -1, vmax = 1)\n",
    "    axs[1, i].set_title(str((select_time[i])),fontdict={'fontsize': 20})\n",
    "    ##NOTEARS plot\n",
    "    NOTEARS_graph=result_NOTEARS[:,actual_time,:,:].mean(axis=0).T\n",
    "    NOTEARS_graph[abs(NOTEARS_graph)<0.2]=0\n",
    "    axs[2, i].matshow(NOTEARS_graph, cmap = 'bwr', vmin = -1, vmax = 1)\n",
    "    ##DYNOTEARS plot\n",
    "    DYNOTEARS_graph=result_dynotears[:,actual_time,:,:].mean(axis=0).T\n",
    "    DYNOTEARS_graph[abs(DYNOTEARS_graph)<0.2]=0\n",
    "    axs[3, i].matshow(DYNOTEARS_graph, cmap = 'bwr', vmin = -1, vmax = 1)\n",
    "    ##proposed plot-nolag\n",
    "    proposed_graph=result_new[:,actual_time,:,:].mean(axis=0).T\n",
    "    proposed_graph[abs(proposed_graph)<0.2]=0\n",
    "    axs[4, i].matshow(proposed_graph, cmap = 'bwr', vmin = -1, vmax = 1)\n",
    "    ##True plot\n",
    "    np.random.seed(123456)\n",
    "    base_DAG=simulate_random_dag(5,4)\n",
    "    base_DAG[pick_1]=cos(i+1)##edited to be coeffcient with error\n",
    "    base_DAG[pick_2]=quadratic(i+1)###multiple\n",
    "    base_DAG[abs(base_DAG)<0.2] = 0\n",
    "    axs[5, i].matshow(base_DAG, cmap = 'bwr', vmin = -1, vmax = 1)\n",
    "for j in range(len(methods)):\n",
    "    axs[j, 0].set(ylabel=methods[j])\n",
    "    axs[j, 0].yaxis.label.set_size(20)\n",
    "for i in range(len(methods)):\n",
    "    for j in range(4):\n",
    "        axs[i][j].get_xaxis().set_ticks([])\n",
    "        axs[i][j].get_yaxis().set_ticks([])\n",
    "plt.savefig(\"S2_nolag_graph.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c7bb718f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_list_proposed=[]\n",
    "MSE_list_dynotears=[]\n",
    "MSE_list_ANOCA=[]\n",
    "MSE_list_NOTEARS=[]\n",
    "MSE_list_DAGGNN=[]\n",
    "for j in range(30):\n",
    "    MSE_list_dynotears.append(mean((result_dynotears[j,:,3,0]-[quadratic(i) for i in range(10)])**2))\n",
    "    MSE_list_proposed.append(mean((result_new[j,:,3,0]-[quadratic(i) for i in range(10)])**2))\n",
    "    MSE_list_ANOCA.append(mean((result_ANOCA[j,:,0,3]-[quadratic(i) for i in range(10)])**2))\n",
    "    MSE_list_DAGGNN.append(mean((result_DAGGNN[j,:,3,0]-[quadratic(i) for i in range(10)])**2))\n",
    "    MSE_list_NOTEARS.append(mean((result_NOTEARS[j,:,3,0]-[quadratic(i) for i in range(10)])**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "67a57668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dynotears 0.5 0.004\n",
      "proposed 0.08 0.005\n",
      "ANOCA 0.15 0.013\n",
      "NOTEARS 0.52 0.006\n",
      "DAGGNN 0.84 0.028\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "print(\"dynotears\",round(mean(MSE_list_dynotears),2), round(statistics.pstdev(MSE_list_dynotears)/math.sqrt(30),3))\n",
    "print(\"proposed\",round(mean(MSE_list_proposed),2), round(statistics.pstdev(MSE_list_proposed)/math.sqrt(30),3))\n",
    "print(\"ANOCA\",round(mean(MSE_list_ANOCA),2), round(statistics.pstdev(MSE_list_ANOCA)/math.sqrt(30),3))\n",
    "print(\"NOTEARS\",round(mean(MSE_list_NOTEARS),2), round(statistics.pstdev(MSE_list_NOTEARS)/math.sqrt(30),3))\n",
    "print(\"DAGGNN\",round(mean(MSE_list_DAGGNN),2), round(statistics.pstdev(MSE_list_DAGGNN)/math.sqrt(30),3))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Copy of 100_rep_simulation_dim_5-cos_error.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
